[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ManyBabies 5: Hunter & Ames Model of Infant Attention - Lab Manual",
    "section": "",
    "text": "Preface",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "index.html#important-note-this-lab-manual-is-still-under-development",
    "href": "index.html#important-note-this-lab-manual-is-still-under-development",
    "title": "ManyBabies 5: Hunter & Ames Model of Infant Attention - Lab Manual",
    "section": "IMPORTANT NOTE! This lab manual is still UNDER DEVELOPMENT!",
    "text": "IMPORTANT NOTE! This lab manual is still UNDER DEVELOPMENT!\n\nBear with us as we finalize this document with all of the information your lab will need to successfully collect data for MB5. Feel free to poke around, and if you have any questions or need help, email us at mb5@manybabies.org.\n\n\nThank you for contributing to ManyBabies 5, a project of ManyBabies!\nMB5 is a cross-lab effort to provide an empirical basis for discussions of replicability as well as cultural, developmental, and methodological variability in infant perception/cognition research. In this project, we are examining drivers of infants’ familiarity vs. novelty preference through a collaboratively-designed “best test” of a popular model of infants’ visual preference for familiar and novel stimuli (Hunter & Ames, 1988). More details about the background, design and hypotheses can be found in the Registered Report (Kosie et al., n.d.). In the following sections, we provide instructions on how to implement the experiment in your lab and report data back to the project as a whole. Thanks for joining us!\n\n\n\n\n\n\nFigure 1: Hunter and Ames model of infant attention (adapted from Bergmann and Cristia, 2016)\n\n\n\n\nThis is a Quarto book.\nTo learn more about Quarto books visit https://quarto.org/docs/books.\n\nThis work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.\n\n\n\n\n\nHunter, M. A., & Ames, E. W. (1988). A multifactor model of infant preferences for novel and familiar stimuli (pp. 69–95). Ablex Publishing.\n\n\nKosie, J., Zettersten, M., Abu-Zhaya, R., Amso, D., Babineau, M., Baumgartner, H., Bazhydai, M., Belia, M., Benavides, S., Bergmann, C., Berteletti, I., Black, A. K., Borges, P., Borovsky, A., Byers-Heinlein, K., Cabrera, L., Calignano, G., Cao, A., Cox, C. M. M., … Lew-Williams, C. (n.d.). ManyBabies 5: A large-scale investigation of the proposed shift from familiarity preference to novelty preference in infant looking time. https://doi.org/10.31234/osf.io/ck3vd",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "contact-info.html",
    "href": "contact-info.html",
    "title": "1  Contact info and important links",
    "section": "",
    "text": "Contact info",
    "crumbs": [
      "General information",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Contact info and important links</span>"
    ]
  },
  {
    "objectID": "contact-info.html#contact-info",
    "href": "contact-info.html#contact-info",
    "title": "1  Contact info and important links",
    "section": "",
    "text": "General inquiries: mb5@manybabies.org\nJessica Kosie (Project Lead): jkosie@asu.edu\nMartin Zettersten (Project Lead): mzettersten@ucsd.edu\nCasey Lew-Williams (Project Lead): caseylw@princeton.edu\nHeidi Baumgartner (MB Exec. Director & MB5 Coordinator): heidib@manybabies.org",
    "crumbs": [
      "General information",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Contact info and important links</span>"
    ]
  },
  {
    "objectID": "contact-info.html#project-listserv",
    "href": "contact-info.html#project-listserv",
    "title": "1  Contact info and important links",
    "section": "Project listserv",
    "text": "Project listserv\n\nMB5 project listserv: mb5-list@manybabies.org\n\nSUBSCRIBE (click on “Join group” using a google-linked account, or email mb5@manybabies.org to request to join)",
    "crumbs": [
      "General information",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Contact info and important links</span>"
    ]
  },
  {
    "objectID": "contact-info.html#important-links",
    "href": "contact-info.html#important-links",
    "title": "1  Contact info and important links",
    "section": "Important links",
    "text": "Important links\n\nMB5 project website: manybabies.org/MB5\nMB5 Stage 1 Registered Report: https://doi.org/10.31234/osf.io/ck3vd\nMB5 Lab Manual (this document): manybabies.org/mb5-manual\nMB5 collaboration agreement: link to google doc (note: the MB5 collaboration agreement can also be found in the Appendix of this manual)\nTo report issues with data collection, deviations from protocol, etc.: MB issue tracker form\nTo upload required documentation (e.g., lab questionnaire): MB5 documentation upload form\nTo upload data: MB5 data upload form",
    "crumbs": [
      "General information",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Contact info and important links</span>"
    ]
  },
  {
    "objectID": "test-dates.html",
    "href": "test-dates.html",
    "title": "2  Data collection period",
    "section": "",
    "text": "MB5 data collection is scheduled to run between the following dates:\n\nStart Date: 2024-MM-DD\n\n\nEnd Date: 2025-MM-DD\n\nIt is essential that all participating labs do their best to collect data prior to the End Date. However, we understand that there may be disruptions to data collection for various reasons.\nIf you are having trouble meeting this deadline, please alert the leadership team (mb5@manybabies.org) as soon as possible to discuss options.\n\nLabs may join the MB5 project any time during the data collection period, provided:\n\nthey commit to completing data collection by the specified end date, AND\na formal “green-light” for testing is obtained from project leadership",
    "crumbs": [
      "General information",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data collection period</span>"
    ]
  },
  {
    "objectID": "lab-overview.html",
    "href": "lab-overview.html",
    "title": "3  MB5 Lab Participation Overview",
    "section": "",
    "text": "These are the steps that every data-collecting lab must follow to participate in MB5. This is just an overview of the process. More detail for each numbered item is available in the linked sections.\n\nBEFORE you do ANYTHING else:\n\nComplete the ManyBabies 5 Lab Sign-Up Form.\nRead the MB5 Collaboration Agreement.\nRead this manual start to finish\nReview the information in the ManyBabies General Manual regarding ethical research, authorship, data sharing, and data use.\n\n\n\nBEFORE you begin data collection:\n\nSet up the experiment in consultation with this lab manual.\n\nDecide on your planned sample size/stopping rule (see Participants and recruitment).\nCarefully record any needed deviations from the protocol using the MB5 issue tracker form.\n\nComplete the MB5 Laboratory Questionnaire [INSERT LINK],\nSubmit your ethics approval, demographics questionnaire, and any other documentation/materials using the MB5 documentation upload form.\nCreate and submit your walkthrough video.\nRun pilot sample through the Data Validator.\nSend email to mb5@manybabies.org to let the leadership team know that you are ready for “green-lighting”.\nWAIT for your official “green-light” from the leadership team to begin data collection.\n\n\nIMPORTANT: DO NOT begin data collection (other than piloting) until you have been explicitly (and individually) “green-lighted” to do so.\n\n\n\nData collection:\n\nCollect your data!\n\n\n\nAFTER you finish data collection:\n\nCompile your participant and trial data files in consultation with the data reporting instructions [Data reporting guidelines].\nSubmit your data using the MB5 data upload form.\nReport individual contributions using the MB Contribution Reporting Form",
    "crumbs": [
      "General information",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>MB5 Lab Participation Overview</span>"
    ]
  },
  {
    "objectID": "getting-started.html",
    "href": "getting-started.html",
    "title": "4  Pre-testing steps",
    "section": "",
    "text": "This section covers some basic aspects of the project that you’ll need to know about BEFORE you set up and run the experiment. Use the arrows to continue to through the sections, or jump to a section using the links below.\n\nGreen-lighting process\nDemographics questionnaire\nEthics approval information\nWalkthrough videos",
    "crumbs": [
      "Getting started",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Pre-testing steps</span>"
    ]
  },
  {
    "objectID": "green-lighting.html",
    "href": "green-lighting.html",
    "title": "5  Green-lighting process",
    "section": "",
    "text": "All labs must complete a series of preparation steps, referred to by MB as the “green-lighting” process, before collecting data for any ManyBabies project. These steps are outlined in the [MB5 Lab Overview](# and in detail throughout the following sections of this manual, but in essence this involves:\n\nproviding required documentation (e.g., ethics approval, lab-specific Demographics Questionnaire)\ndemonstrating correct implementation of the testing procedure\nsubmitting a walkthrough video of the lab’s consent and testing procedure\nsucessfully running pilot data through the MB Data Validator\n\n\nIMPORTANT: DO NOT collect experimental data for MB5 until you have received a “green-light” from the MB5 Project Leads!",
    "crumbs": [
      "Getting started",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Green-lighting process</span>"
    ]
  },
  {
    "objectID": "demographics.html",
    "href": "demographics.html",
    "title": "6  Demographics Questionnaire",
    "section": "",
    "text": "6.1 Collecting participant information\nPlease use the MB5 Demographics Questionnaire1 to collect information about the participant and their family. While parents/guardians can choose to not respond to individual questions, please check the form BEFORE THE RESPONDANT LEAVES YOUR LAB to avoid accidental blank responses.",
    "crumbs": [
      "Getting started",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Demographics Questionnaire</span>"
    ]
  },
  {
    "objectID": "demographics.html#collecting-participant-information",
    "href": "demographics.html#collecting-participant-information",
    "title": "6  Demographics Questionnaire",
    "section": "",
    "text": "1 This questionnaire is adapted from the template(s) created by the MB-Demographics group. Please see Singh et al. (2024) for more information on the development of the template.\nAdaptations and translations\nAs noted in Singh et al. (2024), the questionnaire was developed to query information pertaining to six contructs (biographical information, gestational status, health status, community of descent, caregiving environment, and socioeconomic status). We have added a few additional questions that are of particular interest to MB5 (e.g., family history of colorblindness).\nWe recognize that the specific questions/response options on the example template (which was developed for use in the United States) are not appropriate for all contexts.\nWe encourage labs to adapt the questionnaire template as needed, while keeping in mind the goal of querying the same constructs included in the original template to ensure consistency in reporting. For example, the question on race/ethnicity can be adapted to meet the norms of your region. If possible, please use racial/ethnic categories taken from local census categories. For countries where it is not considered socially or legally acceptable to inquire about ethnic background, please adapt to a more appropriate question (e.g. parent and child place of birth), if possible.If you have any questions about adapting the questionnaire, please contact the leadership team to discuss your concerns. Let us know if any of the questions are unclear to you - it is important that you are able to answer any questions the participants may have. Translations/adaptations of the MB5 Demographics Questionnaire will be available here as they are created.2\n2 Translations/adaptations of the MB-Demographics template are available via the MB-Demographics OSF repository.",
    "crumbs": [
      "Getting started",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Demographics Questionnaire</span>"
    ]
  },
  {
    "objectID": "demographics.html#uploading-demographics-questionnaire",
    "href": "demographics.html#uploading-demographics-questionnaire",
    "title": "6  Demographics Questionnaire",
    "section": "6.2 Uploading demographics questionnaire",
    "text": "6.2 Uploading demographics questionnaire\nAll labs must upload a blank copy of the Demographics Questionnaire they will be using for MB5 via the MB5 documentation upload form.\nPlease ensure that all uploaded materials are clearly labeled in the filename with your LabID (e.g. babylabPrinceton_demographics.pdf). Check the list of LabIDs to confirm your lab’s unique LabID before uploading.\n\n\n\n\nSingh, L., Barokova, M. D., Baumgartner, H. A., Lopera-Perez, D. C., Omane, P. O., Sheskin, M., Yuen, F. L., Wu, Y., Alcock, K. J., Altmann, E. C., Bazhydai, M., Carstensen, A., Chan, K. C. J., Chuan-Peng, H., Dal Ben, R., Franchin, L., Kosie, J. E., Lew-Williams, C., Okocha, A., … Frank, M. C. (2024). A unified approach to demographic data collection for research with young children across diverse cultures. Developmental Psychology, 60. https://doi.org/10.1037/dev0001623",
    "crumbs": [
      "Getting started",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Demographics Questionnaire</span>"
    ]
  },
  {
    "objectID": "ethics.html",
    "href": "ethics.html",
    "title": "7  Ethics approval",
    "section": "",
    "text": "7.1 Overview\nAll data-collecting labs are required to obtain ethics approval from their local oversight board (e.g., IRB)1. As this process can take time, it is a good idea to get started on your ethics approval application as soon as possible. Approvals must be in place and a copy submitted via the process described below before you can obtain a green light to collect data. Contact us if you need advice or help with obtaining ethics approval.",
    "crumbs": [
      "Getting started",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Ethics approval</span>"
    ]
  },
  {
    "objectID": "ethics.html#overview",
    "href": "ethics.html#overview",
    "title": "7  Ethics approval",
    "section": "",
    "text": "1 If your lab/institution does not have a formal ethics oversight board, please refer to MB’s general ethics guidance and contact the Project Leads to confirm ethics compliance\nIn some cases, labs will already have approval for MB5 under an “umbrella protocol” (i.e., a protocol that covers multiple studies in one lab). In these cases, the ethics form should still be uploaded as described below.",
    "crumbs": [
      "Getting started",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Ethics approval</span>"
    ]
  },
  {
    "objectID": "ethics.html#permission-to-collectshare-demographic-data",
    "href": "ethics.html#permission-to-collectshare-demographic-data",
    "title": "7  Ethics approval",
    "section": "7.2 Permission to collect/share demographic data",
    "text": "7.2 Permission to collect/share demographic data\nMB5 (and other ManyBabies projects) ask labs to collect a number of demographic background variables (e.g., gestational age, sex, parental education, community of descent) to be shared along with the main data (after full de-identification is confirmed) (see MB5 Demographics Questionnaire for more information). Not all of those variables are part of the main analysis. Even so, it is highly relevant to collect them for describing our sample, for follow-up and secondary analyses, and for checking the representativeness of the sample.\n\nPlease make sure you have permission to publicly share anonymized raw data (including required demographic info), as this is a condition of participation.\nContact us mb5@manybabies.org if your ethics board raises concerns about collecting and/or sharing these data.",
    "crumbs": [
      "Getting started",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Ethics approval</span>"
    ]
  },
  {
    "objectID": "ethics.html#permission-to-share-video-recordings",
    "href": "ethics.html#permission-to-share-video-recordings",
    "title": "7  Ethics approval",
    "section": "7.3 Permission to share video recordings",
    "text": "7.3 Permission to share video recordings\nWe strongly encourage labs (where possible) to store and share video recordings of their testing sessions on Databrary, which is a secure site created for this purpose. Databrary allows for different levels of privacy: fully private (available only to the uploading research group), shared only with Databrary-approved researchers, or fully open. You will need to ensure that you have ethics approval in place to upload and/or share recordings, and collect specific consent for this purpose from your participants’ parents/guardians. In addition, you will need to become a member of Databrary, which requires approval from your institution, so it’s helpful to start this process early. You can begin the registration process for Databrary here. We are aware that many laboratories, particularly those based in the European Union, may not be allowed to use Databrary. In these circumstances we encourage labs to use alternative methods for sharing their videos where possible.",
    "crumbs": [
      "Getting started",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Ethics approval</span>"
    ]
  },
  {
    "objectID": "ethics.html#ethics-upload",
    "href": "ethics.html#ethics-upload",
    "title": "7  Ethics approval",
    "section": "7.4 Uploading ethics approval documentation",
    "text": "7.4 Uploading ethics approval documentation\nEthics documentation (e.g., proof of IRB approval) must be submitted to the MB5 leads prior to data collection. Submit your lab’s ethics approval documentation using the MB5 documentation upload form.\nPlease ensure that all uploaded materials are clearly labeled in the filename with your LabID (e.g. babylabPrinceton_ethics.pdf). Check the list of LabIDs to confirm your lab’s unique LabID before uploading.",
    "crumbs": [
      "Getting started",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Ethics approval</span>"
    ]
  },
  {
    "objectID": "walkthrough.html",
    "href": "walkthrough.html",
    "title": "8  Walkthrough Videos",
    "section": "",
    "text": "8.1 Purpose\nThe purpose walkthrough videos is two-fold:\nPlease rest assured that these videos will NOT be used by ManyBabies to critique individual researchers’ laboratory policies and procedures. This project is a community effort!",
    "crumbs": [
      "Getting started",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Walkthrough Videos</span>"
    ]
  },
  {
    "objectID": "walkthrough.html#purpose",
    "href": "walkthrough.html#purpose",
    "title": "8  Walkthrough Videos",
    "section": "",
    "text": "Given the ManyBabies Consortium’s commitment to Open Science, we would like to have a full and accurate record of how the study was implemented in each laboratory.\nOne of the goals of ManyBabies is to study how methodological variation affects experimental outcomes in infant research. This video record may be used for analyses examining whether laboratories with different characteristics and procedures (e.g., larger or smaller test booths, white or black walls) differ in the effect size obtained in ManyBabies projects.",
    "crumbs": [
      "Getting started",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Walkthrough Videos</span>"
    ]
  },
  {
    "objectID": "walkthrough.html#method",
    "href": "walkthrough.html#method",
    "title": "8  Walkthrough Videos",
    "section": "8.2 Method",
    "text": "8.2 Method\nThere are two possibilities to create a video documenting your process:\n\nFilming a (preferably pilot) session with a participant (with parental approval and permission from your local ethics board). Please make sure you have permission to share this video fully publicly!!\nAsking a colleague to “play” parent and using a dummy (e.g., a doll) as a baby stand-in.\n\nIF YOUR FINAL VERSION IS NOT READY FOR PRIME TIME, FEAR NOT. The goal is to be informative, not flawless - it can have starts and stops and disfluency.",
    "crumbs": [
      "Getting started",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Walkthrough Videos</span>"
    ]
  },
  {
    "objectID": "walkthrough.html#consent",
    "href": "walkthrough.html#consent",
    "title": "8  Walkthrough Videos",
    "section": "8.3 Consent",
    "text": "8.3 Consent\nNote that we plan to share the videos among the consortium via Databrary, our website, and/or YouTube. There should be no assumption of privacy, and no confidential or otherwise sensitive information should be included in the videos. Be sure that parental consent covers all these options when filming participants.",
    "crumbs": [
      "Getting started",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Walkthrough Videos</span>"
    ]
  },
  {
    "objectID": "walkthrough.html#sequence",
    "href": "walkthrough.html#sequence",
    "title": "8  Walkthrough Videos",
    "section": "8.4 Sequence",
    "text": "8.4 Sequence\nMake sure your video covers the following components. We added questions you should answer for each step. It is not necessary to narrate your video (you can if you want); a silent observer is sufficient, but be sure to cover all details requested below. If your lab language is not English, we might add subtitles later on.\n\nGreeting\n\nWhere do you receive families? (Dedicated area, parking lot, general entrance)\nWho is there? (Parents, colleagues, assistants)\nWhat do you say and ask them? (Example: Do you check when the baby last ate / slept?)\nWhat do you do if a baby arrives asleep or fussy?\n\n\n\nBriefing before testing\n\nWhat instructions do you give to the parents? Are there any specific instructions on how to behave, sit, hold the baby, etc?\nHow detailed do you explain the procedure and aim of the study?\nWhat is your informed consenting process like? How do parents give consent? When do you typically obtain consent?\n\n\n\nTest\n\nWhat does your testing room/booth look like (size, lay-out, etc.)? Try to film the entrance and complete interior of the test booth or room\nWhere is the baby sitting (e.g., parent’s lap, high chair, etc.)? Film the seating arrangement before the baby is seating and with the baby\nWhat does the stimulus display look like (size, distance to baby)? Where are the screen(s)/lamps located? 4. Where is the experimenter located during testing (e.g., inside or outside the booth)? Show where the experimenter is sitting; if it is in the same room, capture both baby and experimenter.\nCan the baby see the experimenter during testing? How does the experimenter see the baby? (e.g.,videofeed)\nIf live-coding takes place: Show examples of what counts as a look / no look and/or videotape someone doing the coding together with the infant looks.\nHow is the experimenter blinded to trial type during testing?\nHos is the parent blinded during testing (blacked-out glasses or something similar)?\n\n\n\nQuestionnaire(s)\n\nAt what point do you hand out/collect questionnaires (e.g., pre- or post-experiment)?\nDo you give any additional instructions other than those listed on the form(s)?\n\n\n\nDebrief after experiment\n\nWhat do you tell parents at the end of a study?\nAre there standard questions you ask them?",
    "crumbs": [
      "Getting started",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Walkthrough Videos</span>"
    ]
  },
  {
    "objectID": "walkthrough.html#upload-your-walkthrough-video",
    "href": "walkthrough.html#upload-your-walkthrough-video",
    "title": "8  Walkthrough Videos",
    "section": "8.5 Upload your walkthrough video",
    "text": "8.5 Upload your walkthrough video\n\nUpload your walkthrough video here\n\nPlease ensure that your video is clearly labeled in the file name with your LabID (e.g. babylabPrinceton_walkthrough.mpg).\nYou are welcome to view videos that have already been uploaded by other labs as examples (note that these videos might not have been reviewed yet by project leads for completeness)\nWalkthrough videos from MB1 are available on Databrary",
    "crumbs": [
      "Getting started",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Walkthrough Videos</span>"
    ]
  },
  {
    "objectID": "experiment-overview.html",
    "href": "experiment-overview.html",
    "title": "9  Experiment Overview",
    "section": "",
    "text": "9.1\nEach baby will be presented with a series of 12 trials with one familiarization and two test phases each. During familiarization, a single stimulus is presented centrally on the screen. The test phase will consist of two stimuli, one familiar and one novel, presented side-by-side. The location of the stimuli will be switched in the two test trials. The duration of the familiarization will vary across trials (5, 10, or 15s). The tests will last 5s each. There will be two versions of the experiment: one in which the familiarization time will be pre-established (fixed-length), and another one in which the length of the trial will last until the infant accumulates the required looking time (infant-controlled).",
    "crumbs": [
      "Setting up the experiment",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Experiment Overview</span>"
    ]
  },
  {
    "objectID": "experiment-overview.html#section",
    "href": "experiment-overview.html#section",
    "title": "9  Experiment Overview",
    "section": "",
    "text": "Equipment and sofware\nStimuli\nProcedure\nParticipants and recruitment\nData validation",
    "crumbs": [
      "Setting up the experiment",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Experiment Overview</span>"
    ]
  },
  {
    "objectID": "equipment.html",
    "href": "equipment.html",
    "title": "10  Equipment and software",
    "section": "",
    "text": "10.1 Equipment\nThe minimal equipment required to run this experiment is:\nAddional (optional) equipment:",
    "crumbs": [
      "Setting up the experiment",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Equipment and software</span>"
    ]
  },
  {
    "objectID": "equipment.html#equipment",
    "href": "equipment.html#equipment",
    "title": "10  Equipment and software",
    "section": "",
    "text": "Computer running experiment software (see below)\nMonitor/television for stimulus display\nCamera for capturing infant looking behavior1\nMixer for syncing recording of infant with stimulus timing (or other method for doing so)\n\n1 not needed if infant’s face is captured by eye tracker\n\nEye tracker\nBlacked-out glasses for parent to wear during experiment",
    "crumbs": [
      "Setting up the experiment",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Equipment and software</span>"
    ]
  },
  {
    "objectID": "equipment.html#software",
    "href": "equipment.html#software",
    "title": "10  Equipment and software",
    "section": "10.2 Software",
    "text": "10.2 Software\nWe assume you will use an experimental software (e.g. Matlab, Habit, E-Prime, Psychopy, OpenSesame or custom software) to run the study and one of two settings to record looking times: (1) Offline Video recording (2) Eye-tracker (e.g. Tobii, EyeLink, SMI, ASL, or a different company, with appropriate software from the eye-tracker or custom software). (3) Eye-tracker + video recording. We also assume you know how to set up looking-time studies on your equipment. If that is not the case, or if you need help, support is available from the following people:\n\nPsychoPy:\nPyHab:\nTobii:\nEyelink:\nOther systems: email us mb5@manybabies.org and we’ll do our best to help out",
    "crumbs": [
      "Setting up the experiment",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Equipment and software</span>"
    ]
  },
  {
    "objectID": "stimuli.html",
    "href": "stimuli.html",
    "title": "11  Stimuli",
    "section": "",
    "text": "11.1 Overview\nBecause the sample size possible in ManyBabies projects provides a unique opportunity to test generalizability across multiple stimulus types, we chose two different categories of stimuli: Fribbuli1 and Fractals. These two classes of stimuli were chosen because: (1) they allow for variation in stimulus complexity within the same stimulus category (i.e., by manipulating the number of features); (2) infants are unlikely to have previous experience with either set of stimuli; and (3) the inclusion of two stimulus sets allow us to begin examining the generalizability of any observed effect.\nWe created 12 unique Fribbuli and 12 unique Fractals, operationalizing complexity as the number of features present (these features are appendages in the case of Fribbuli and iterations of the same structure for Fractals; see Figure 3). Within each stimulus type, 6 items were designed to be low-complexity and 6 were designed to be high-complexity",
    "crumbs": [
      "Setting up the experiment",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Stimuli</span>"
    ]
  },
  {
    "objectID": "stimuli.html#overview",
    "href": "stimuli.html#overview",
    "title": "11  Stimuli",
    "section": "",
    "text": "All materials are available in the MB5 materials directory.\n\n\n1 “Fribbuli” is a portmenteau combining the words “Fribble” and “stimuli”. These stimuli were inspired by the Fribbles stimulus set (Barry et al., 2014)\n\nManyFribbuli2\nFribbuli are colorful, computer-generated models of 3D figures. All Fribbuli are made up of one of twelve possible body shapes and one (low-complexity) or four (high-complexity) appendages.\nADD MORE INFO ABOUT COLOR SELECTION, SIZING, ETC\n\n2 We’re calling our custom sets of stimuli “ManyFribbuli” and “ManyFractals” because… well, it’s fun.\nManyFractals\nFractals are geometric shapes in which the same structure is repeated iteratively at different levels of scale.\nADD MORE INFO ABOUT FRACTAL GENERATION\n\n\nAttention-getter stimuli\n\nBetween Trials: Please use the provided “laughing baby” stimulus to re-center babies between each trial (i.e., before familiarization begins). If your lab uses a different attention-getting stimulus that you feel is more appropriate for your community, please check with us.\nWithin Trial: Please use the the “Hoehle circle with chimes” stimulus to re-center babies within each trial (i.e., between familiarization and test and between test phases 1 and 2).\n\n\n\n\n\nBarry, T. J., Griffith, J. W., De Rossi, S., & Hermans, D. (2014). Meet the fribbles: Novel stimuli for use within behavioural research. Frontiers in Psychology, 5. https://doi.org/10.3389/fpsyg.2014.00103",
    "crumbs": [
      "Setting up the experiment",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Stimuli</span>"
    ]
  },
  {
    "objectID": "procedure.html",
    "href": "procedure.html",
    "title": "12  Procedure",
    "section": "",
    "text": "12.1 Trial Structure\nThere are a total of 12 trials for each infant. Each trial will include both familiarization and test phases (described in further detail below). Between each trial, a “laughing baby” attention-getter will be presented.",
    "crumbs": [
      "Setting up the experiment",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Procedure</span>"
    ]
  },
  {
    "objectID": "procedure.html#overview",
    "href": "procedure.html#overview",
    "title": "12  Procedure",
    "section": "12.2 Overview",
    "text": "12.2 Overview\nDuring the experiment, infants will be seated on their caregiver’s lap or in a high-chair or car seat (whichever option corresponds to a lab’s standard procedures for testing infants, as reported in the pre-data-collection survey). Each trial is made up of a familiarization phase, in which infants are first exposed to a stimulus, followed by two test phases where infants are presented with both the item they viewed during the familiarization phase (the familiar item) and a novel test item. These phases will be repeated on each of 12 total trials.\n\n\n\n\n\n\nFigure 12.1: This figure depicts the design of an example trial. At familiarization, a single image is shown for 5, 10, or 15 s. After the desired familiarization time is reached (based on the infant-controlled or fixed-length design criteria), infants are presented with a central fixation stimulus for 500 ms. During the two test phases (5 s each), infants view the same image to which they were familiarized paired with a new stimulus from the same set (e.g., Fribbuli or Fractals) and the same level of complexity. The side on which the familiar and novel images are presented is counterbalanced across test phases, but the images remain the same.",
    "crumbs": [
      "Setting up the experiment",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Procedure</span>"
    ]
  },
  {
    "objectID": "procedure.html#familiarization-phase",
    "href": "procedure.html#familiarization-phase",
    "title": "12  Procedure",
    "section": "12.3 Familiarization Phase",
    "text": "12.3 Familiarization Phase\nThere are a total of 12 familiarization events for each infant that vary across three dimensions (see table 12.1):\n\nStimulus class (Fribbuli or Fractals)\nComplexity level (low or high); and\nFamiliarization time (5s, 10s, or 15s)1\n\n1 Familiarization can be achieved either by ending the familiarization phase of an experiment after infants have acquired a certain amount of looking at the target (i.e., an infant-controlled design), or by presenting the familiarization phase for a fixed amount of exposure (i.e., a fixed-length design).2 Participating labs are encouraged to use an infant-controlled procedure, if possible.\nInfant-Controlled Familiarization2\nIf you are running the infant-controlled version of the study, infants may accumulate the required familiarization time across multiple looks before advancing to the test phase. The familiarlization image will remain on the screen until the infant has reached the target familiarization time (as determined by an experiment coding infant looking).\nWe will additionally implement a maximum trial length criterion; if infants do not accumulate the required looking time within twice the target familiarization time (i.e., 10, 20, or 30s), the familiarization phase will end.\n\n\nFixed-Length Familiarization\nIf you are unable to collect infant-controlled accumulated looking for familiarization trials, then you will present the familiarization trials for a fixed length of time before advancing to the test trial.\n\n\n\n\n\nTable 12.1: Familarization events (Note: Order of events will be randomized for each pariticipant)\n\n\n\n\n\n\n\n\n\n\n\n\nEvent\nFamiliarization Time (s)\nStimulus Class\nComplexity Level\nExample Stimulus\n\n\n\n\n1  2  3\n5  10  15\n Fribbuli\n Low\n\n\n\n4  5  6\n5  10  15\n Fribbuli\n High\n\n\n\n7  8  9\n5  10  15\n Fractals\n Low\n\n\n\n10  11  12\n5  10  15\n Fractals\n High",
    "crumbs": [
      "Setting up the experiment",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Procedure</span>"
    ]
  },
  {
    "objectID": "procedure.html#test-phase",
    "href": "procedure.html#test-phase",
    "title": "12  Procedure",
    "section": "12.4 Test Phase",
    "text": "12.4 Test Phase\nOnce the familiarization criterion has been reached, the infant will be presented with a central-fixation stimulus (looming circle) for 500 ms. The central-fixation stimulus will be immediately followed by the paired test stimuli. Each pair of test stimuli includes the stimulus to which the infant was familiarized and a novel stimulus from the same stimulus class (Fribbuli or Fractals) and complexity level (low-complexity or high-complexity). Infants will view the test stimuli for a total of 10s, separated into two sub-phases. They will be presented with the familiar and novel stimulus for 5s after which a central fixation stimulus will be presented. The infant will then view the second 5s test phase, which uses the same two stimuli but with the location flipped (i.e., the image that was on the left in phase 1 will be on the right in phase 2).",
    "crumbs": [
      "Setting up the experiment",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Procedure</span>"
    ]
  },
  {
    "objectID": "participants.html",
    "href": "participants.html",
    "title": "13  Participants and recruitment",
    "section": "",
    "text": "13.1 Age and sample size\nThe expected lab contribution is a full sample of 32 babies (preferred, if possible) or a half sample of 16 babies (minimum).",
    "crumbs": [
      "Setting up the experiment",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Participants and recruitment</span>"
    ]
  },
  {
    "objectID": "participants.html#age-and-sample-size",
    "href": "participants.html#age-and-sample-size",
    "title": "13  Participants and recruitment",
    "section": "",
    "text": "Minimum age: 3 months, 0 days\n\n\nMaximum age: 15 months, 0 days\n\nFor example, on a testing date of 2025-04-15, eligible infants would have birthdays on or between 2024-01-15 and 2025-01-15.\n\nYou can use an online tool such as this Age Calculator to use the infant’s date of birth and testing date to determine eligibility and calculate age in days, which is the required format for age reporting. \n\n\nNotes about age and sample size:\n\nTry to distribute participants across the full range of ages, if possible.\nA lab’s sample size contribution includes any infant who enters the laboratory, even if they are eventually excluded (e.g., due to fussiness, experimenter error, too young or too old, etc.).\nIn situations where labs plan but are unable to collect the minimum contribution (16 babies), lab members will still be eligible for authorship. Alternative contributions may be requested by the Project Leads in these circumstances.",
    "crumbs": [
      "Setting up the experiment",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Participants and recruitment</span>"
    ]
  },
  {
    "objectID": "participants.html#eligibility-and-exclusions",
    "href": "participants.html#eligibility-and-exclusions",
    "title": "13  Participants and recruitment",
    "section": "13.2 Eligibility and Exclusions",
    "text": "13.2 Eligibility and Exclusions\n\nThe only requirements for inclusion in MB5 are:\n\nthe infant’s age falls within the 3- to 15-month age range AND\nthe infant has no known issues that would directly impede their ability to process visual stimuli\n\nInfants with other characteristics that are commonly used as exclusion criteria in developmental studies (e.g., hard of hearing, premature, bilingual, etc.) can be included in the sample.\nPlease determine participants’ eligibility on the phone prior to scheduling them in the ManyBabies study to avoid testing ineligible participants, but note that the inclusion criteria for MB5 are much more inclusive than typical in-lab studies (described above). Participants who come into the lab who are subsequently determined to be ineligible should be still reported in the sample but clearly marked as ineligible based on age or visual processing impairment (see [Data reporting guidelines][Data reporting guidelines] for more info).",
    "crumbs": [
      "Setting up the experiment",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Participants and recruitment</span>"
    ]
  },
  {
    "objectID": "participants.html#first-sessionsecond-session-policy",
    "href": "participants.html#first-sessionsecond-session-policy",
    "title": "13  Participants and recruitment",
    "section": "13.3 First-session/second-session policy",
    "text": "13.3 First-session/second-session policy\nSome laboratories have the practice of testing babies in more than one study during the same visit.\n\n‘First session’ refers to babies tested soon upon arrival to the lab, prior to participating in any other studies.\n‘Second session’ refers to any testing that is done after the first session.\n\nPlease contribute ‘first session’ babies when possible. It is possible that second session babies will contribute worse/weaker/different data with respect to the larger goals of determining effect sizes.\nLabel ‘second session’ babies appropriately if infants were run in a different study on the same visit prior to their participation in MB5. Please also document the nature of the study run prior to MB5 for all ‘second session’ participants (e.g., “7 minute study of object categorization using eye-tracking”).",
    "crumbs": [
      "Setting up the experiment",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Participants and recruitment</span>"
    ]
  },
  {
    "objectID": "participants.html#peeking-and-stopping-rules",
    "href": "participants.html#peeking-and-stopping-rules",
    "title": "13  Participants and recruitment",
    "section": "13.4 Peeking and stopping rules",
    "text": "13.4 Peeking and stopping rules\nIn your initial commitment to a recruitment block (in the laboratory questionnaire), you will document your recruitment practices, your initial plan regarding how many babies you will run and of what type, as well as your stopping rule (e.g. stop when I reach the specified N, stop when the study data collection time ends). It is important to document any changes to your recruitment/stopping rule with a “protocol change form”. IMPORTANT: It is critical for the integrity of the data analysis that you NOT base any decisions about how many babies to run on the data being generated in your lab, or on the number of participant exclusions. Laboratories should stick with their original “stopping rule” - whether based on a number of participants or testing time frame. However, we recognize that this may not always be possible. In extraordinary circumstances, decisions about changes to the sample size and stopping rule must be made by someone who has not viewed the emerging data. You can look (if necessary, e.g. to support a student interim report) but you MUST NOT change your recruitment goals and strategy based on your view of the data. Doing this will compromise the goals of the project! If you change your recruitment based on the data, that invalidates the statistical inferences we want to make and introduces exactly the kinds of biases into the data that this project was designed to avoid. If your lab is running pre-specified pilot participants (e.g., to practice the procedure), you may make minor procedural adjustments during that period only.",
    "crumbs": [
      "Setting up the experiment",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Participants and recruitment</span>"
    ]
  },
  {
    "objectID": "prior-to-data-coll-checklist.html",
    "href": "prior-to-data-coll-checklist.html",
    "title": "15  Prior to data collection checklist",
    "section": "",
    "text": "The steps for getting started are tracked by the MB5 leadership team on the MB5 Project Tracker. You can check it to see what steps your lab has completed. If you have any questions or think your lab’s progress is not up-to-date, contact us (mb5@manybabies.org).\nAfter preparing your lab and BEFORE BEGINNING DATA COLLECTION you need to:\n\nComplete the Initial Sign-Up Form (if you have not already done so).\nConfirm ethics approval is uploaded: Make sure that a copy of your lab’s ethics approval is in this google drive folder. If you plan to share participant videos via Databrary, you should also make sure you are getting proper consent for video sharing (please include approval for video sharing in ethics upload).\nConfirm demographics form is uploaded: Make sure that a copy of your lab’s demographics formethics approval is in this google drive folder.\nConfirm walkthrough video is and demographics form uploaded (if needed): Make sure that a copy of your lab’s walkthrough video is in this google drive folder, and your laboratory demographics form in this google drive folder.\nComplete the Lab Questionnaire: Make sure someone from your lab has filled out the Lab Questionnaire with details about your laboratory. The leadership will be notified of your submission of the Lab Questionnaire after which they will start the approval/greenlighting process.\nConvert dummy or pilot data into the right format for submission (see details below) using the MB Data validator to check data validity; in case of questions, please contact the analysis team. This ensures that you will be ready to submit your lab’s data to the central analysis team!\nSend email to Jessica Kosie (jkosie@asu.edu) to let the leadership know that you are ready for ‘greenlighting’.\nWait until you receive an official go-ahead from Project Leads before you begin testing. We may have questions for you, e.g. about your planned protocol deviations. We will do our best to respond quickly, but Iif you don’t hear from us within a week of sending the email, please contact us again!.",
    "crumbs": [
      "Setting up the experiment",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Prior to data collection checklist</span>"
    ]
  },
  {
    "objectID": "general-lab-practices.html",
    "href": "general-lab-practices.html",
    "title": "16  General Lab Practices",
    "section": "",
    "text": "16.1 Training research assistants\nYou are responsible for implementing rigorous training practices. Research assistants should be held to the same high standards for ManyBabies as they would be for your main studies. You are free to have any number of research assistants conduct the test sessions, but please aim for as much coding consistency as possible and document which research assistant coded a given baby (using code names such as RA1, RA2, etc. if you wish). You will be asked to report about your standard training practices (e.g., how/when do you determine it’s okay for a research assistant to test real babies). Online Coding. If you are using a central screen to gather accumulated looking data for infant-controlled familiarization, then research assistants will need to be properly trained in coding online looking behaviors. Offline Coding. If you are not using an eyetracker to gather data, then you will need to code the test trials offline.",
    "crumbs": [
      "Running the experiment",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>General Lab Practices</span>"
    ]
  },
  {
    "objectID": "general-lab-practices.html#greeting-families",
    "href": "general-lab-practices.html#greeting-families",
    "title": "16  General Lab Practices",
    "section": "16.2 Greeting families",
    "text": "16.2 Greeting families\nYou can greet families, briefly explain the study’s purpose and goals in terms understandable to families (avoid technical jargon), obtain informed consent, and conduct the appointment as you normally would. Acknowledge their decision to consider participating and express appreciation for their time. Address potential concerns families might have and answer their questions openly and honestly.",
    "crumbs": [
      "Running the experiment",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>General Lab Practices</span>"
    ]
  },
  {
    "objectID": "general-lab-practices.html#compensating-families",
    "href": "general-lab-practices.html#compensating-families",
    "title": "16  General Lab Practices",
    "section": "16.3 Compensating families",
    "text": "16.3 Compensating families\nYou can use your lab’s standard, IRB-approved method for compensating families. This can include providinge small gifts, cash, travel reimbursement, taxi rides, or other incentives for participation as you normally would. Participating labs are responsible for compensating their own participants.",
    "crumbs": [
      "Running the experiment",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>General Lab Practices</span>"
    ]
  },
  {
    "objectID": "conditions.html",
    "href": "conditions.html",
    "title": "17  Testing conditions",
    "section": "",
    "text": "17.1 Piloting and other non-primary data\nSome labs might wish to pilot their design on a small number of infants in order to work out problems with the setup and allow experimenters to practice the protocol. Piloting with this purpose is indeed encouraged! It is critical to the integrity of the ManyBabies project that these pilot data are carefully differentiated from your main contribution. You do NOT need to report pilot data in your spreadsheet, but if you do, please ensure that you properly mark them as such in the designated Pilot column. You must make an explicit decision to begin non-pilot data collection at a particular date - this decision cannot be retroactive, and cannot be based on inspection of the pilot data (i.e., you cannot choose to include a pilot participant in the actual sample if the data “looks good”). Some labs might plan to test additional babies beyond the primary sample (e.g., with additional manipulations). These data will not be included in our primary planned analyses, and will not count toward the minimum contribution, but these additional datasets are welcome, and we encourage researchers to preregister other hypotheses. You are free to publish these “side studies” on your own terms, but please keep in mind the restrictions on publishing the main dataset if you are using it as a comparison/control sample (see the section on Open Science Policies in the MB General Manual).",
    "crumbs": [
      "Running the experiment",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Testing conditions</span>"
    ]
  },
  {
    "objectID": "conditions.html#piloting-and-other-non-primary-data",
    "href": "conditions.html#piloting-and-other-non-primary-data",
    "title": "17  Testing conditions",
    "section": "",
    "text": "Caregiver bias and instruction\nCaregivers should be masked from viewing the visual stimulus using your lab’s standard method (e.g., having caregivers wear taped-over sunglasses). It is not necessary to block parents’ hearing of the audio stimulus. Instruct parents NOT to point to the lights or screen, shift their bodies, or move their chairs if the baby is inattentive. Emphasize during the instruction/setup that infants’ boredom with some of the stimuli is part of the experiment and is OK. Suggestion: to ensure that the infant and parent are as comfortable as possible, you may tell the parent that it is okay to shift their or their baby’s body to a more comfortable position, or provide interaction that the baby is soliciting, but emphasize that this may be done only for a short period during the attention grabber phase (e.g., when they hear the laughing baby).\n\n\nCollecting participant information\nWe aim to integrate our testing procedure with your lab’s procedure as much as possible, but there is some amount of information that we need to gather in a standardized fashion.\nParticipant information: Please use this Family Background Questionnaire to collect the information. You are welcome to adapt the format as long as the wording is not changed, except as noted: Any areas marked in green you can adapt to ensure they are appropriate to your country/region. However, please keep the wording as similar as possible to ensure consistency in reporting. The question on race/ethnicity can be adapted to meet the norms of your region. If possible, please use racial/ethnic categories taken from local census categories. For countries where it is not considered socially or legally acceptable to inquire about ethnic background, please adapt to a more appropriate question (e.g. parent and child place of birth), if possible. Translations into other languages will be available here as they are created. If you need to make changes other than as indicated above, please contact the leadership team to discuss your concerns. Let us know if any of the questions are unclear to you - it is important that you are able to answer any questions the participants may have. Please also check the participants’ answers to avoid blank responses. If you modify any of the wording in the form, even in the green sections, or translate the form to your lab’s local language please upload a blank copy of your form using the MB5 documentation upload form. Please ensure that your form is clearly labeled in the filename with your LabID (e.g. babylabPrinceton_background.pdf).\n\n\nExperimenter blindness\nThe experimenter should be masked fromblind to trial details, by being either (1) in a different room, with no way of knowing which stimuli the baby is seeing on each trial, or (2) in the same room but facing away from the stimuli and unaware of what is on the screen.\n\n\nSound volume\nYour lab can use whatever volume level has been used successfully in the past, but please standardize your volume for this study so that every baby gets stimuli at the same volume.",
    "crumbs": [
      "Running the experiment",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Testing conditions</span>"
    ]
  },
  {
    "objectID": "during-data-collection.html",
    "href": "during-data-collection.html",
    "title": "18  During data collection",
    "section": "",
    "text": "18.1 Restarts, recalibration (eye-tracker) and pauses\nAny pauses in the procedure can potentially lead to an erasure of the weak memory trace for the familiarization stimuli (Gerken, p.c. noticed a loss of effect if there is a 30+ second pause between familiarization and test phase). Therefore, we ask: NO RESTARTS. Do not restart any trials, regardless of short looking, fussiness, experimental error, etc. Very short trials will be excluded centrally during the analysis process, but should be fully reported and not repeated. DO NOT RECALIBRATE (eyetrackers) once the session has started. Pauses: If babies are fussy, it can be necessary to attempt to get them settled. You may use the natural pause of an attention getter to let the parent non-verbally resettle their baby for a very short time (a couple of seconds, according to your practices). However, longer pauses should result in the cessation of the study. Suggestion: if the baby is fussy and you would like to try to continue the experiment after the baby calms down just so that the parent gets the full experience, you are welcome to do so, but this data must be excluded. For these babies, you would report any data collected before the actual experiment terminated from fuss-out/inattention, not the repeat or continued demonstration.",
    "crumbs": [
      "Running the experiment",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>During data collection</span>"
    ]
  },
  {
    "objectID": "during-data-collection.html#exclusions-and-reporting-errors-and-infant-fuss-outs",
    "href": "during-data-collection.html#exclusions-and-reporting-errors-and-infant-fuss-outs",
    "title": "18  During data collection",
    "section": "18.2 Exclusions and reporting errors and infant “fuss-outs”",
    "text": "18.2 Exclusions and reporting errors and infant “fuss-outs”\nDecisions regarding discards for experimental reasons will be made centrally and need to be reported consistently, hence it is important to retain all data from all infants that entered the testing room. Specifically, the data you send in for central analysis should use the “toe in the testing room” standard: if the infant made it so far as the testing room, the Pparticipant Data files dataset should include their data. In ManyBabies studies, we do not discard “partial data.” It is important for both reporting purposes and potential secondary analyses to have full information about both “usable” and “unusable” trials, even for infants who did not complete or provide usable data for all familiarization and test trials. Trial-level exclusions may not result in the exclusion of the participant from the dataset. These instructions are counter to many labs’ normal internal practices, so please ensure that RAs are fully trained on this element. There are specific columns in the data templates to report the reasons that some of this data should not be included in the main analysis; every lab is expected to report at least some ‘unusable’ data!\n\nSession-level and trial-level errors\nThere are two possible kinds of exclusion: session-level (exclude all data from this participant from analysis) and trial-level (exclude just this trial, e.g. because there was interference or the baby had already fussed out). Session-level errors are reported in the Participant Data file and trial-level errors are reported in the Trial Data file. Most lab-reported errors will be “trial-level” errors. If the infant completed any trials, please do NOT report the infant as a session-level error EVEN IF YOU LATER REALIZE THE CHILD DOES NOT MEET ALL INCLUSION CRITERIA. Medical issues and developmental concerns. Please do not exclude based on medical issues / developmental concerns. Instead, provide sufficient detail in the ‘medical_issue’and/or ’developmental_concern’ fields for the analysis team to review and categorize centrally. As with all exclusions, it is important to include these in your data if the infant entered the testing room.\nFor clear-cut judgements such as age, please just use the appropriate columns to report the values that would result in exclusion (e.g. “age = 3 years”). For subjective judgements such as whether the baby was too fussy, the central decision will be made based on the original coder/RA’s judgment, since it would be impractical to review comments/videos and make the decision centrally. Therefore, please be very clear (but succinct) in the ‘trial_error_info’ and ‘session_error_info’ fields about whether a given trial should be discarded and why. Please classify as one of the listed ‘Value example’ options in the Data Dictionary where possible. Use the “other” category sparingly and only if absolutely necessary. In the ‘notes’ column, please provide further succinct but sufficient information so that it is clear why a given trial or infant was excluded (e.g. “mom pointed at the screen”). Remember that this will be the only information that will be available to the analysis team as they compile and analyze the dataset; ambiguous entries will be problematic for data analysis!\n\nSession-level errors\nSession level errors are those which result in discarding the data for a participant completely. Session level errors include: Fuss-out after entering the testing room but prior to starting the experiment Parental interference affecting ALL trials (e.g. caregiver refuses to wear the eye covering properly through all trials, or chronically failing to comply with experimenter instructions such that the validity of the entire session is in question). Experimenter error that makes the entire session unuseable (e.g. ran the wrong test session). Equipment failure that makes the entire session unuseable (e.g. video was not playing properly) Failure to calibrate (eyetrackers only) Infant was tested but was found to not meet the inclusion criteria (e.g. vision issues reported on the demographics questionnaire). Only in cases where infants did not start the experiment (i.e., did not see any stimuli) due to fuss-out or equipment/calibration failure, labs are welcome to reschedule the appointment to another occasion; please indicate this in the participant data form. With regards to session-level errors: Please make sure to include participants excluded for session-level errors in your Participant Data file. You do not need to report them in the Trial Data file (see below for details about the required formats of these files). Data from infants where session-level errors are reported do NOT count towards the minimum sample size. Please do NOT mark a participant as a “session-level” error if an infant entered the testing room and completed the first familiarization phase even if they provided no usable test trial data.\n\n\nTrial-level errors:\nTrial-level errors are those which result in discarding the data for a single trial. Each of the 12 test trials should be marked as either ‘no error’ (usable) or ‘error’ (to be discarded). Trials with no usable data should have ‘NA’ marked in their data columns. Your lab will make the decision and report whether a trial should be excluded, as well as the reason why. These can include temporary instances of issues such as: parental interference in the middle of the experiment (e.g. mother speaks to infant during a trial and gets their attention) experimenter error or equipment failure that affects one or more trials but not the entire session transitory infant fussiness involving only a very brief pause in testing (see below for further details on reporting), or fussiness where the infant “fusses out” after the initiation of one or more test trials With regards to trial-level errors note: For transitory fussiness, ONLY mark the trials on which the infant was actually fussy - further exclusions may be implemented centrally, but it is important that any potentially usable trials after a transitory fussiness period be included in the submitted data. For example, if the infant was fussy on trials 8 and 10 but not trials 1-7,9,11 and 12, only trials 8 and 10 should be marked as an exclusion. If the infant provides some usable trials and then “fusses out” so that the study is terminated prematurely, please make this clear by marking ‘NA’ on trials that were not given.\n\nTrial level errors resulting in further exclusion:\nIn most cases, trial level exclusions should result in exclusion ONLY of the trial immediately impacted by the exclusion (e.g. transitory fussiness, parent distracting baby by scratching their nose). However, in some cases, it may be necessary to exclude all subsequent trials, because of concerns that the infant is no longer “on task”. If this is the case, please mark all subsequent trials as trial level errors and explain the reasoning in the notes. Some examples of this type of situation: Any time (due to fussiness or other reasons) there is a break between trials of more than a few seconds. Equipment failure that raises concerns about the validity of subsequent trials. Significant parental interference/engagement or external noise that diverts the infant’s attention to the extent that it raises concerns about the infant being distracted across all trials. Note that we have included a test in the robustness checking section of the manuscript about the effect of discarding trials after an initial excluded trial.",
    "crumbs": [
      "Running the experiment",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>During data collection</span>"
    ]
  },
  {
    "objectID": "after-data-collection.html",
    "href": "after-data-collection.html",
    "title": "19  After data collection",
    "section": "",
    "text": "19.1 Data reporting guidelines\nParticipant data from all infants entering the lab needs to be reported. Even if the infant fusses out prior to entering the testing room/booth, the data for that infant should be submitted. In the case of fuss-out prior to entering the testing room, only participant data needs to be provided. In all other cases, trial level data also needs to be reported (In some cases it may be the case that all trial data will be missing as indicated by ‘NA’). This provides valuable information for, e.g., secondary analyses regarding fuss-out rates and the timing of fuss-out in the experiment. Data collected after the study has been terminated (e.g. fussy babies who are brought back in for a “second run”) should not be reported; any data collected prior to the complete fuss-out needs to be reported in the usual manner. If you report pilot data, make sure this is indicated as such in the ‘Pilot’ column of the data table. Below instructions are designed to help you share data with the MB5 project team in a format that will minimize analysis errors and maximize the ease of merging datasets from many different labs.",
    "crumbs": [
      "After data collection",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>After data collection</span>"
    ]
  },
  {
    "objectID": "after-data-collection.html#data-templates",
    "href": "after-data-collection.html#data-templates",
    "title": "19  After data collection",
    "section": "19.2 Data templates",
    "text": "19.2 Data templates\nThe primary deliverables for the project are two data files, filled out by your lab from the templates provided below. Please download a copy of each template and use a guide for formatting your lab’s data. We prefer files in the CSV data format. PLEASE NOTE that saving in this format will remove any formulas or other non-plain-text features of your spreadsheet (e.g,. color fills, formatting); all information should be captured in the text within each cell.\nParticipant Data – A .csv file with one row for each participant, and with columns showing the participant’s subject number, age, demographic information, notes on the session, etc. Participant Data - CSV template Trial Data – A .csv file with one row for each trial, and with columns showing the participant’s subject number, trial number, trial type, looking time, etc. Trial Data - CSV template IMPORTANT NOTE 1: These two files must use identical, anonymous subject identifiers (‘participant_id’). We must be able to link participant- and trial-level data across files! You can use your lab’s normal participant numbering convention (e.g., 001, 002, 003, etc.), as long as participant IDs DO NOT include any private information (e.g., initials, birth date, gender). IMPORTANT NOTE 2: These files must contain de-identified data ONLY. All potentially identifying information should be stripped from your data file before submission. For example, you SHOULD NOT include birth date and test date in your Participant Data file. Instead, use an age calculating tool (e.g., https://www.calculator.net/age-calculator.html) to calculate each participant’s age in days, and report that value in the ‘participant_age_days’ variable. If you have any questions about ensuring your data is de-identified, email contact@manybabies.org. IMPORTANT NOTE 3: It’s really important to remember that these files are designed to be read by a computer program, not a person. So anything that violates the template (e.g., variables that aren’t of the specified type, formatting, comments, etc.) will not work. For example, cells in the column “lang1_exposure” in the participant data file should contain numbers. If you write “80 to 90” this will cause errors because it contains characters in addition to numbers (note: please check questionnaire responses before participants leave the lab to avoid NA responses). If you have questions, comments, or calculations, please communicate directly with the analysis team, rather than embedding them in the data. IMPORTANT NOTE 4: Please do not leave any fields blank. If something does not logically have an answer, or if you did not collect this information, please mark it as “NA”. Language. If you collect data from children who are learning more than one language, please provide an approximate percentage of exposure to each language, either by parental report, or if it is standard practice in your lab, using a day-in-the-life style questionnaire administered by the RA. The total should add up to 100%.",
    "crumbs": [
      "After data collection",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>After data collection</span>"
    ]
  },
  {
    "objectID": "after-data-collection.html#data-dictionary",
    "href": "after-data-collection.html#data-dictionary",
    "title": "19  After data collection",
    "section": "19.3 Data dictionary",
    "text": "19.3 Data dictionary\nMB5 Data Dictionary – This spreadsheet lists all of the variables that need to go into the Participant Data and Trial Data files (Note that there is one worksheet/tab for each data file). Each row contains a variable and that variable’s specified format (e.g., string, integer), set of example values, and description. It is important that your lab’s data follows these specifications exactly in order to allow for data harmonization with the full dataset. MB5 Data Dictionary",
    "crumbs": [
      "After data collection",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>After data collection</span>"
    ]
  },
  {
    "objectID": "after-data-collection.html#data-validation",
    "href": "after-data-collection.html#data-validation",
    "title": "19  After data collection",
    "section": "19.4 Data Validation",
    "text": "19.4 Data Validation\nAfter preparing your Participant Data and Trial Data files, please use the MB Data Validator to ensure your lab’s data is in the correct format (MB Validator User Manual). Common issues: If the validator is rejecting your CSV file, it may be due to different country standards around the use of commas as decimal points, etc. in your numeric format. Please use periods (‘.’) and not commas (‘,’) as decimal points. Make sure that there are no stray marks in cells outside of your data range. For example, a space entered in a cell in an otherwise empty row or column will cause an error. If you encounter any unexpected issues please send an email to Martin Zettersten (martincz@princeton.edu). Your data files MUST pass validation before submission.",
    "crumbs": [
      "After data collection",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>After data collection</span>"
    ]
  },
  {
    "objectID": "after-data-collection.html#data-submission",
    "href": "after-data-collection.html#data-submission",
    "title": "19  After data collection",
    "section": "19.5 Data submission",
    "text": "19.5 Data submission\nOnce your data files have passed validation, please upload both the Participant Dataand Trial Data files using the MB5 Data Upload form. Please take note of the following: It is essential that both file names include your ManyBabies LabID. Refer to the LabID list here to find your lab’s unique LabID. Use the following naming convention for your Participant and Trial Data files: yourLabID_participant_data.csv (e.g., babylabPrinceton_participant_data.csv) yourLabID_trial_data.csv (e.g., babylabPrinceton_trial_data.csv)\n\nSharing ‘raw’ data\nFor most labs, the “raw” data generated by the software that runs the study will be in a different format from the one we are asking labs to submit as their machine-readable, de-identified data. This creates a problem for reproducibility of the data pipeline. In addition to potential error-checking, the raw data may be useful for secondary analysis. Secondary analyses can be used to map variability between labs. Ideally, we would ask all labs to share both their actual raw data (immediately generated when the study is run) together with any code they use to convert it to the submission format. However, doing so would likely raise concerns about the sharing of de-identified data as these raw data outputs may contain birthdates or other participant-identifying information. A related concern is that many labs may be converting the raw data into the submission formatted files by hand, which may be prone to human error. We strongly encourage labs to develop processes for making these conversions in an automated way (e.g., in an R script). In the coming months we will be soliciting suggestions and reviewing the practicality of helping labs develop these practices, as well as making a decision about whether and how to collect raw data from labs that do not use eyetrackers. We welcome comments and suggestions from contributors on this issue!\n\nSubmitting raw eye-tracking data\nThere are additional considerations for labs submitting eye-tracking data. First, the raw data is useful for studying variability between labs in the extraction of looking times. Second, the pupil size data provides interesting additional information about cognitive processing that can be used in follow-up or spin-off studies. We are therefore asking all laboratories submitting eye-tracking data to provide these raw data. For the data to be most useful and accessible for secondary analyses, the preferred format is to submit 1) CSV or TSV files (or any other plain text format); please select the export options so that the file remains as unchanged as possible (select all possible variables, no fixation filters, etc.) and 2) annotated R-code (or other script) that transforms these CSV or TSV files into the trial-level format that needs to be submitted. Please upload these files using the MB5 Data Upload form in addition to the Participant Data and Trial Data files (see above for details). For purposes of transparency and replicability, using a standardized format for the eye-tracking data is preferable (e.g., the Peekbank format). Please take care that the raw eye-tracking data does not contain any identifying information such as birth dates, zip codes, etc.! If you have any concerns regarding the sharing of your raw data (e.g. with respect to participant consent/ethics approval), please contact the project leaders. In the Lab Questionnaire, report which method you used to compute the looking times In your upload, please also include the (annotated!) script that was used to compute the looking times from the raw data",
    "crumbs": [
      "After data collection",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>After data collection</span>"
    ]
  },
  {
    "objectID": "after-data-collection.html#video-records-of-data-collection-optional",
    "href": "after-data-collection.html#video-records-of-data-collection-optional",
    "title": "19  After data collection",
    "section": "19.6 Video records of data collection (optional)",
    "text": "19.6 Video records of data collection (optional)\nIf you are sharing videos of your data collection (and this is strongly encouraged, if it’s at all possible given your ethics approval), you can store them in Databrary if you are a member. The naming convention for Databrary volumes is “ManyBabies5: yourLabID” (e.g. “ManyBabies5: babylabPrinceton”). We ask that you use this naming convention so people can easily search for all the ManyBabies-related volumes.",
    "crumbs": [
      "After data collection",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>After data collection</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Barry, T. J., Griffith, J. W., De Rossi, S., & Hermans, D. (2014).\nMeet the fribbles: Novel stimuli for use within behavioural research.\nFrontiers in Psychology, 5. https://doi.org/10.3389/fpsyg.2014.00103\n\n\nHunter, M. A., & Ames, E. W. (1988). A multifactor model of\ninfant preferences for novel and familiar stimuli (pp. 69–95).\nAblex Publishing.\n\n\nKosie, J., Zettersten, M., Abu-Zhaya, R., Amso, D., Babineau, M.,\nBaumgartner, H., Bazhydai, M., Belia, M., Benavides, S., Bergmann, C.,\nBerteletti, I., Black, A. K., Borges, P., Borovsky, A., Byers-Heinlein,\nK., Cabrera, L., Calignano, G., Cao, A., Cox, C. M. M., … Lew-Williams,\nC. (n.d.). ManyBabies 5: A large-scale investigation of the proposed\nshift from familiarity preference to novelty preference in infant\nlooking time. https://doi.org/10.31234/osf.io/ck3vd\n\n\nSingh, L., Barokova, M. D., Baumgartner, H. A., Lopera-Perez, D. C.,\nOmane, P. O., Sheskin, M., Yuen, F. L., Wu, Y., Alcock, K. J., Altmann,\nE. C., Bazhydai, M., Carstensen, A., Chan, K. C. J., Chuan-Peng, H., Dal\nBen, R., Franchin, L., Kosie, J. E., Lew-Williams, C., Okocha, A., …\nFrank, M. C. (2024). A unified approach to demographic data collection\nfor research with young children across diverse cultures.\nDevelopmental Psychology, 60. https://doi.org/10.1037/dev0001623",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "collab-agreement.html",
    "href": "collab-agreement.html",
    "title": "appendix A — Collaboration Agreement",
    "section": "",
    "text": "ManyBabies 5 Collaboration Agreement\nThis agreement describes how work on the ManyBabies 5 project will be structured and credited. The purpose of this agreement is to clarify contributor roles and expectations in the interest of transparency.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Collaboration Agreement</span>"
    ]
  },
  {
    "objectID": "collab-agreement.html#conduct",
    "href": "collab-agreement.html#conduct",
    "title": "appendix A — Collaboration Agreement",
    "section": "Conduct",
    "text": "Conduct\nEach contributor is personally accountable for the accuracy and integrity of their work on this project. This includes ensuring that (1) you are operating in accordance with your local research rules and regulations and global norms of research ethics (e.g., Declaration of Helsinki), (2) you abide by the MB Code of Conduct and this Collaboration Agreement at all times during your participation, (3) your specific research products are honest and accurate (e.g., data, translations, code), and (4) your description of your role on the project is accurate. Contributors should indicate their agreement to the Code of Conduct and Collaboration Agreement by completing the MB CRediT Self-Report Form at the onset of their project participation (see Authorship section below for more details).\nAll projects should comply with the ManyBabies Code of Conduct. Project Leads are responsible for ensuring that all project contributors have read and agreed to comply with the Code of Conduct and this Collaboration Agreement before initiating involvement in the project.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Collaboration Agreement</span>"
    ]
  },
  {
    "objectID": "collab-agreement.html#anticipated-products",
    "href": "collab-agreement.html#anticipated-products",
    "title": "appendix A — Collaboration Agreement",
    "section": "Anticipated products",
    "text": "Anticipated products\nWe anticipate that this project will result in:\n\nA paper to be preprinted at PsyArXiv and submitted to the journal Nature Human Behaviour\nMultiple conference presentations\nStimuli, experiment software, and an experiment protocol to be shared on Open Science Framework (OSF) for reuse after the preprint is published\nRaw video data (from labs with permission to share and parental consent), to be shared on Databrary and indexed with the label “ManyBabies5”\nLooking-time data, to be shared via GitHub and/or OSF\nParticipant information (de-identified), such as age and language exposure, to be shared via GitHub and/or OSF\nAnalysis code, to be shared via GitHub and/or OSF\n\nThese anticipated products might change/evolve over the course of the project and are meant to serve as an expected set of products rather than an exhaustive list. Contributors will be notified of any updates or changes to anticipated products via the project listserv.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Collaboration Agreement</span>"
    ]
  },
  {
    "objectID": "collab-agreement.html#roles-and-responsibilities",
    "href": "collab-agreement.html#roles-and-responsibilities",
    "title": "appendix A — Collaboration Agreement",
    "section": "Roles and responsibilities",
    "text": "Roles and responsibilities\nAll project contributors are expected to abide by this Collaboration Agreement regardless of contribution role, and to self-report contributions accurately using the MB Contribution Reporting form. We welcome individuals making contributions in more than one domain, and note that data collection is not a required contribution for authorship (see Authorship section for more information). Please make sure that you report any changes to your role in a timely manner to ensure that you get proper credit for all of your contributions.\nBelow is information about specific project roles and their respective responsibilities.\n\nProject Leads\n\nFormulating the research goals and aims\nProviding repeated opportunities for scholars of any career stage to contribute to the project\nCreating, maintaining, and sharing project-specific documentation (Collaboration Agreement, Lab Manual, etc.)\nOrganizing project-specific information on OSF, Google Drive, GitHub, etc.\nDocumenting project progress from beginning to end, including timely website and newsletter updates\nCoordinating the work of all other teams via regular meetings and check-ins\nEnsuring that MB policies are followed\nCoordinating the organization of lab IRB ethics approval documents\nActively answering project-related questions\nSupporting exchanges on Slack or other communications platform that aids project administration (e.g. ensuring that questions about procedure and setup are answered)\nCoordinating manuscript submission and pre-print services\nEnsuring that all study materials (e.g., stimuli, analysis code, anonymized data) are properly archived and publicly accessible at the earliest possible stage, and at the time of publication at the latest\n\n\n\nMethodology Team\n\nDeveloping study materials (e.g., stimuli, experiment files, questionnaires) and procedure(s)\nProviding all scripts used during stimulus creation, and exhaustively documenting all reasoning behind stimulus creation and selection decisions\nLeading the coordination of materials translation and adaptation as needed\nProviding clear instructions on how to set up the study for participating labs\n\nThese instructions should be publicly available at the time of publication and allow for a direct replication\n\nTroubleshooting methodology issues as needed\nContributing to the Method section of the manuscript\nReviewing and (if desired) providing feedback on the remainder of the original and revised manuscript\nMaintaining regular communication with the Project Leads\n\n\n\nData Collection Teams\n*Note: The expectation is that each data-collecting laboratory will be represented in authorship by one or two researchers (e.g., a lab PI who oversees data collection, and a student or RA who is primarily responsible for data collection). Requests to include more than two researchers from a lab must be approved by Project Leads.\n\nObtaining and documenting ethics approval for data collection, as locally appropriate\nCreating and sharing a short “walkthrough video” of lab set-up and testing procedure, as appropriate\nEnsuring that all ManyBabies and project-specific data collection guidelines (e.g., collecting data from the agreed-upon number of participants, following stopping rules, submitting data from any infant who enters the lab) are followed\nEnsuring all ethical practices (e.g. properly obtaining consent, anonymizing data as needed, etc.) are followed\nMaking reasonable efforts to check and ensure data quality (e.g., checking manual data entry, documenting issues reported by research assistants and participants)\nFollowing data formatting guidelines and confirming correct formatting by using the MB Data Validator prior to submission\nDocumenting and reporting issues to the Project Leads\nAssisting with materials translations\nResponding efficiently to project-related correspondence\nReviewing and (if desired) providing feedback on the original and revised manuscript\nEnsuring all authors on the team maintain an active email contact on the project mailing list until the project is fully complete (normally the time that the peer-reviewed manuscript proofs have been finalized)\n\n\n\nData Analysis Team\n\nSetting up the data validator and creating a data template for data collection teams\nSpecifying in detail the confirmatory analyses for Stage 1 submission, together with analysis code, and (where possible) analyzing pilot data to illustrate its appropriateness\nConducting a power analysis to estimate the required sample size prior to the Registered Report submission\nAnalyzing data and (in collaboration with Project Leads) coordinating external code review, and (normally) writing the Results section of the peer-reviewed manuscript.\nSharing analysis code (with clear comments) publicly via GitHub or a similar service (linked to OSF)\nEnsuring that shared data are fully anonymized prior to public release\nContributing to the Analysis Plan section of the Registered Report and the Results section of the Stage 2 manuscript\nReviewing and (if desired) providing feedback on the remainder of the original and revised manuscript\nMaintaining regular communication with the Project Leads\n\n\n\nWriting Team\n\nWriting the original manuscript draft, in consultation and collaboration with the Methodology and Data Analysis Teams\nSoliciting feedback on manuscript drafts and reviewer comments from the full project team\nIncorporating feedback and developing a revised manuscript draft\nMaintaining regular communication with the Project Leads",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Collaboration Agreement</span>"
    ]
  },
  {
    "objectID": "collab-agreement.html#authorship",
    "href": "collab-agreement.html#authorship",
    "title": "appendix A — Collaboration Agreement",
    "section": "Authorship",
    "text": "Authorship\n\nHow do I become an author on a paper that results from this project?\nAll project contributions will be documented via an adaptation of the CRediT taxonomy using an authorship spreadsheet generated from the project’s MB Contribution Reporting Form. All authors, regardless of whether they are part of the writing team, must review the final manuscript and will be given the opportunity to provide feedback prior to submission. In addition, all authors must make a substantive contribution to at least one of the roles outlined above and report their contribution(s) via the corresponding MB CRediT category(s).\nIf you contribute to the project in the manner outlined above, you are eligible for authorship. Contributions will be compiled in the MB CRediT table and this information will be appended to (or referenced in) all relevant scientific products (e.g., manuscript) in accordance with journal guidelines.\nIn general (and except in very limited circumstances), authors will not be added to a manuscript (e.g., Stage 1 Registered Report) between the first submission to a journal and subsequent revisions. In the case that a change to authorship is deemed appropriate by Project Leads, all authors will be notified of the proposed change via project listserv and be given at least one week to object to the change. Depending on the policies of the journal, authorship changes will be (1) approved on behalf of the consortium by the corresponding author (preferred) or, (2) approved by each author individually.\n[Note: Given the nature of MB projects, it is likely that many (if not most) authors will contribute to the project as a member of a data collection team only (corresponding to the “Investigation” CRediT category). For all authors, including those who plan to collect data, authorship on Stage 1 manuscripts will be based on planned contributions and authorship on Stage 2 manuscripts will be based on actual contributions. It is expected that authors will join the project in response to a call for data collectors after the Stage 1 manuscript has been accepted.]\n\n\nHow do we handle dissenting opinions about scientific products?\nIn large-scale collaborations, disagreements are inevitable. Whenever possible, decisions will be made using a consensus-based decision-making process. Project Leads are expected to carefully consider dissenting opinions from collaborators and, to whatever extent is reasonable, discuss the issue with the dissenter and with all active team members/contributors when appropriate. In some cases, decision-making may default to democratic voting; however, this will not always be deemed the best approach. Where consensus can’t be reached, final decisions about the scientific product will ultimately be left to the Project Leads.\n\n\nHow will authorship order be determined?\nAuthorship order will be organized into the following sections, with order determined as listed below:\nSection 1 (First Author(s)): Main proposer(s) (as determined by consensus of Project Leads) listed first, ordered based on contribution, followed by remaining Project Leads, ordered reverse alphabetically.\nSection 2 (Team Leads/Other Significant Contributors): Leaders of working groups (e.g., methods, analysis, writing) and others who have made significant/leading contributions (as determined by Project Leads), ordered reverse alphabetically.\nSection 3 (Other Contributors): Remaining project contributors not specified in other sections, ordered reverse alphabetically.\nSection 4 (Senior Authorship): Project Leads designated as senior authors (as determined by consensus of Project Leads), ordered in reverse based on contributions.\n[Note: A note describing this ordering procedure will be added to the author notes]\n\n\nHow do we handle authorship on secondary papers for this project?\n[For comprehensive information on ManyBabies policy regarding secondary projects, please see the section “Policies on Derived Projects and Presentations” in the MB General Manual.]\nIt is possible that this project results in secondary papers that are based on the project’s research products. Prior to the full public release of the main project, secondary papers should only be initiated with the consent of the Project Leads. After full public release, projects may be freely initiated without any special permissions from the Project Leads. The only exception to these rules are projects with a primarily pedagogical purpose (for example, undergraduate or Master’s theses). These may be initiated at any time without any special permissions from the Project Leads, as long as the written reports based on these projects are not disseminated publicly before the full public release of the main project. If you are working on an educational project and your institution requires posting your thesis to a public repository (such as a library repository), contact the Project Leads for guidance.\nAll secondary projects should be governed by their own collaboration agreement. By default, authors on the main paper will not be counted as authors on secondary papers unless they also become involved in the work of these secondary projects. All secondary papers should cite the primary written public report of the main project.\nAll secondary projects involving ManyBabies collaborators should be announced to the Project Leads and all outputs of secondary projects should be reported to ManyBabies via the activity and initiative tracking form.\n\n\nHow do we handle the use of project materials/data for other derived projects and presentations?\nAll other uses of project materials and/or data (e.g., for department or conference presentations) are subject to ManyBabies’ policies on derived projects and presentations. Please refer to this section in the MB General Manual for more information, and direct all questions to Project Leads and/or the MB Executive Director (contact@manybabies.org)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Collaboration Agreement</span>"
    ]
  },
  {
    "objectID": "collab-agreement.html#press-and-public-reporting-of-manybabies-results",
    "href": "collab-agreement.html#press-and-public-reporting-of-manybabies-results",
    "title": "appendix A — Collaboration Agreement",
    "section": "Press and public reporting of ManyBabies results",
    "text": "Press and public reporting of ManyBabies results\nInitial press releases will be coordinated by the Project Leads and ManyBabies leadership once the paper is accepted or at any time point the leads deem suitable for wider dissemination. All press releases must (a) prominently highlight the role of the MB collaborative network, and (b) link to MB contacts. All collaborators are encouraged to speak to the press, but are expected to (1) emphasize the highly-collaborative nature of the research project and (2) encourage the interviewer to reach out to various members of the team. The content of the press release and paper is embargoed until the time and date clearly stated on the press release.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Collaboration Agreement</span>"
    ]
  },
  {
    "objectID": "collab-agreement.html#changes-to-this-collaboration-agreement",
    "href": "collab-agreement.html#changes-to-this-collaboration-agreement",
    "title": "appendix A — Collaboration Agreement",
    "section": "Changes to this Collaboration Agreement",
    "text": "Changes to this Collaboration Agreement\nAs the project evolves, changes may be made to this collaboration agreement. In those instances, all collaborators will be notified of the change via project listserv and a list of recent changes will be listed at the top of the document. Contributors will have one week from the time of notice to object to changes, and all reasonable efforts will be made by Project Leads to address any concerns/objections. If such concerns/objectives cannot be resolved through discussion and/or mediation, the Governing Board will have final discretion.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Collaboration Agreement</span>"
    ]
  },
  {
    "objectID": "collab-agreement.html#contact-info",
    "href": "collab-agreement.html#contact-info",
    "title": "appendix A — Collaboration Agreement",
    "section": "Contact info",
    "text": "Contact info\nWe encourage you to ask questions and raise concerns about project-related matters as soon as possible. You can direct all questions and concerns to jkosie@asu.edu, mzettersten@ucsd.edu, and/or caseylw@princeton.edu. If you have an issue or concern that you would like addressed by MB leadership, you can contact the MB Executive Director or the MB Governing Board.\n\n\nAuthored by: ManyBabies (adapted from the Psychological Science Accelerator Collaboration Agreement template)\nAmended by: Jessica Kosie, Martin Zettersten, Christina Bergmann, Dima Amso, Casey Lew-Williams\nReviewed by: J.K., M.Z., C.L.-W., Heidi Baumgartner\nDate updated: 2022-04-29",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Collaboration Agreement</span>"
    ]
  }
]