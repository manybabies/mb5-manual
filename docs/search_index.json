[["index.html", "ManyBabies 5 Lab Manual - DRAFT - DO NOT USE Primary Manual for Participating Laboratories Overview Lab Checklist", " ManyBabies 5 Lab Manual - DRAFT - DO NOT USE Primary Manual for Participating Laboratories compiled by ManyBabies 5 Leads Updated: 2024-05-03 Overview Thank you for contributing to ManyBabies 5 (MB5), a project of ManyBabies, a cross-lab effort to provide an empirical basis for discussions of replicability as well as cultural, developmental, and methodological variability in infant perception/cognition research. In this project, we are examining drivers of infants’ familiarity vs. novelty preference through a collaboratively-designed “best test” of a popular model of infants’ visual preference for familiar and novel stimuli (Hunter and Ames 1988). More details about the background, design and hypotheses can be found in the Registered Report. Below we provide instructions on how to implement the experiment in your lab and report data back to the project as a whole. MB5 Project website: manybabies.org/MB5 ManyBabies General Manual: link MB5 Collaboration Agreement: link MB5 Stage 1 Registered Report: (Kosie &amp; Zettersten 2024) MB5 Contact: mb5@manybabies.org Lab Checklist If you are new to MB5, complete the Initial Sign-Up Form. Read this manual start to finish. BEFORE you begin data collection: Please ensure that you have carefully read the MB5 Collaboration Agreement and all of the documentation from the ManyBabies General Manual regarding ethical research, authorship, data sharing, and data use. Set up your study in consultation with this document. Carefully record any needed deviations from the protocol. Decide on your planned sample size/stopping rule. Complete the Laboratory Questionnaire [insert link], submit Ethics approval and other documentation/materials. Create and submit your walkthrough video. Run pilot sample through data validator. Send email to mb5@manybabies.org to let the leadership team know that you are ready for ‘greenlighting’. Wait for your official “greenlight” from the leadership team to begin data collection. Data collection: IMPORTANT: DO NOT begin data collection (other than piloting) until you have been explicitly (and individually) “greenlighted” to do so. Collect your data! AFTER you finish data collection: Complete your participant and trial data files in consultation with the data reporting instructions [insert link]. Submit your data using the MB5 data upload form. References "],["getting-started.html", "1 Getting Started 1.1 Start and End Date 1.2 Ethics approval 1.3 Participants and Recruitment", " 1 Getting Started 1.1 Start and End Date Data collection officially started XXX and will initially run until XXX. Labs may join the MB5 project any time during the data collection period, provided that set-up and a formal “green light” is obtained, and data collection can be completed before the end date. However, we understand that there may be disruptions to data collection for various reasons. If you are having trouble meeting this timeframe, please alert the leadership team to discuss possibilities. 1.2 Ethics approval It is a good idea to get started on your ethics approvals as soon as possible. Approvals must be in place and a copy submitted to the Drive folder (see below) before you can obtain a green light to collect data. Contact us mb5@manybabies.org if you need advice on obtaining ethics approval. MB5 and other ManyBabies projects ask labs to collect a number of demographic background variables to be made public along with the main data, e.g. parental education, sex, etcetera. Not all of those variables are part of the main analysis. Even so, it is highly relevant to collect them for follow-up and secondary analyses, and for checking the representativeness of the sample. Please contact us mb5@manybabies.org if your ethics board raises concerns about collecting these data. Please make sure you have permission to publicly share anonymized raw data (including required demographic info), as this is a condition of participation. 1.2.1 Video sharing We strongly encourage labs (where possible) to store/share video recordings of their testing on Databrary, which is a secure site for this purpose. You will need to ensure that you have ethics approval in place to do this, and collect specific consent for this purpose from your participants. In addition, you will become a member of Databrary, which will require approval from your institution, so it’s helpful to start this process early. You can begin the registration process for Databrary here. We are aware that many laboratories, particularly in the European Union, may not be allowed to use Databrary. In these circumstances we encourage labs to use alternative methods for sharing their videos where possible. 1.2.2 Upload a copy of your ethics approval documentation Ethics documentation (e.g., IRB approval forms) should be submitted prior to data collection. Ethics forms should be uploaded using the MB5 Documentation Upload Form. Please ensure that all materials uploaded for ethics are clearly labeled in the filename with your LabID (e.g. babylabPrinceton_ethics.pdf). Check here for a complete list of LabIDs to confirm yours before uploading. In some cases, labs will already have approval for MB5 under an “umbrella protocol” (i.e., a protocol that covers multiple studies in one lab). In these cases, the ethics form should still be uploaded as described here. 1.3 Participants and Recruitment 1.3.1 Age and numbers The minimum expected contribution is a full sample of 32 babies (preferred, if possible) or a half sample of 16 babies between 3 months, 0 days and 15 months, 0 days old. Try to distribute participant ages across the full range of ages if possible. Please report the exact age in days. You can use an online tool such as: https://www.calculator.net/age-calculator.html In situations where labs planned but were unable to collect the minimum contribution, laboratory members will still be eligible for authorship. Alternative contributions may be requested by the Leadership Team in these circumstances. A lab’s sample size contribution includes any infant who enters the laboratory, even if they are eventually excluded (e.g., due to fussiness, experimenter error, etc). While we encourage as much participation as you can spare, it is crucial to the success of the project that you treat our study with the same care as you would any other study in your lab with respect to recruitment procedures, timing of data collection, and RAs/RA training. Please do not commit to providing data to ManyBabies if this level of care is not possible. 1.3.2 Eligibility and Exclusions The only requirements for inclusion in MB5 are that an infants’ age falls within the 3- to 15-month age range and that the infant has no known issues that would directly impede their ability to process visual stimuli. Infants who are hard of hearing, premature, bilingual, etc can be included in the lab’s sample. Please determine participants’ eligibility on the phone prior to scheduling them in the ManyBabies study to avoid testing ineligible participants, but note that the inclusion criteria for MB5 are much more inclusive than typical in-lab studies (described above). Participants who come into the lab who are subsequently determined to be ineligible should be reported in the sample. 1.3.3 First-session/second-session policy Some laboratories have the practice of testing babies in more than one study during the same visit. ‘First session’ refers to babies tested soon upon arrival to the lab, prior to participating in any other studies. ‘Second session’ refers to any testing that is done after the first session. * Please contribute ‘first session’ babies when possible. It is possible that second session babies will contribute worse/weaker/different data with respect to the larger goals of determining effect sizes. * Please label ‘second session’ babies appropriately if infants were run in a different study on the same visit prior to their participation in MB5. Please also document the nature of the study run prior to MB5 for all ‘second session’ participants (e.g., “7 minute study of object categorization using eye-tracking”). "],["setting-up-the-experiment.html", "2 Setting up the experiment 2.1 Experiment Overview 2.2 Equipment 2.3 Stimuli 2.4 Piloting and other non-primary data 2.5 Procedure 2.6 General lab practices", " 2 Setting up the experiment 2.1 Experiment Overview Each baby will be presented with a series of 12 trials with one familiarization and two test phases each. During familiarization, a single stimulus is presented centrally on the screen. The test phase will consist of two stimuli, one familiar and one novel, presented side-by-side. The location of the stimuli will be switched in the two test trials. The duration of the familiarization will vary across trials (5, 10, or 15s). The tests will last 5s each. There will be two versions of the experiment: one in which the familiarization time will be pre-established (fixed-length), and another one in which the length of the trial will last until the infant accumulates the required looking time (infant-controlled). 2.2 Equipment We assume you will use an experimental software (e.g. Matlab, Habit, E-Prime, Psychopy, OpenSesame or custom software) to run the study and one of two settings to record looking times: (1) Offline Video recording (2) Eye-tracker (e.g. Tobii, EyeLink, SMI, ASL, or a different company, with appropriate software from the eye-tracker or custom software). (3) Eye-tracker + video recording We also assume you know how to set up looking-time studies on your equipment. If that is not the case, or if you need help, support is available from the following people: OpenSesame: E-prime: Andreea Geambasu (a.geambasu@hum.leidenuniv.nl) PsychoPy: Silvia Benavides-Varela (silvia.benavidesvarela@unipd.it). (the psychopy experiment used by Silvia’s group is here for other labs to use) PyHab: Kateřina Chládková chladkova@praha.psu.cas.cz or Katerina.Chladkova@ff.cuni.cz Eye tracking, using Tobii: Sylvain Sirois (sylvain.sirois@uqtr.ca) Eye tracking, using SMI: Eye tracking, using Eyelink: Julien Mayor (julien.mayor@psykologi.uio.no) Other systems: email Casey Lew-Williams (caseylw@princeton.edu) and we’ll do our best to help out. 2.3 Stimuli All materials are available in our google drive folder. Trial Structure. There are a total of 12 trials for each infant. Each trial will include both familiarization and test phases (described in further detail below). Between each trial, a laughing baby attention-getter will be presented. Familiarization Trials. There are a total of 12 familiarization events for each infant that vary across three dimensions: (1) stimulus class (fractals or fribbles) ; (2) complexity level (low or high complexity); and (3) familiarization time (5s, 10s, or 15s); see table below. XXX Infant-controlled Familiarization studies: If you are running the infant-controlled version of the study, infants may accumulate the required familiarization time across multiple exposures before advancing to the test trials. Fixed Familiarization studies: If you are unable to collect infant-controlled accumulated looking for familiarization trials, then you will present the familiarization trials for a fixed length of time in one exposure before advancing to the test trial. Stimulus Class Complexity Level Familiarization Time Fribbles Low Complexity 5 seconds Fribbles Low Complexity 10 seconds Fribbles Low Complexity 15 seconds Fribbles High Complexity 5 seconds Fribbles High Complexity 10 seconds Fribbles High Complexity 15 seconds Fractals Low Complexity 5 seconds Fractals Low Complexity 10 seconds Fractals Low Complexity 15 seconds Fractals High Complexity 5 seconds Fractals High Complexity 10 seconds Fractals High Complexity 15 seconds Test Trials. Once the familiarization criterion has been reached, the infant will be presented with a central fixation stimulus and then paired test stimuli. Each pair of test stimuli includes the stimulus to which the infant was familiarized and a novel stimulus from the same stimulus class (fribbles or fractals) and complexity level (low-complexity or high-complexity). Infants will view the test stimuli for a total of 10s, separated into two phases. They will be presented with the familiar and novel stimulus for 5s after which a central fixation stimulus will be presented. The infant will then view the second 5s test phase, which uses the same two stimuli but with the location flipped (i.e., the image that was on the left in phase 1 will be on the right in phase 2). Re-centering / Attention-getter stimulus Between Trials. Please use the provided laughing baby stimulus to re-center babies between each trial (i.e., before familiarization begins). Within Trial. Please use the provided attention-getter stimulus (the Hoehle circle with chimes) to re-center babies within each trial (i.e., between familiarization and test and between each of the test phases). See below for a visualization of the trial structure: 2.4 Piloting and other non-primary data Some labs might wish to pilot their design on a small number of infants in order to work out problems with the setup and allow experimenters to practice the protocol. Piloting with this purpose is indeed encouraged! It is critical to the integrity of the ManyBabies project that these pilot data are carefully differentiated from your main contribution. You do NOT need to report pilot data in your spreadsheet, but if you do, please ensure that you properly mark them as such in the designated Pilot column. You must make an explicit decision to begin non-pilot data collection at a particular date - this decision cannot be retroactive, and cannot be based on inspection of the pilot data (i.e., you cannot choose to include a pilot participant in the actual sample if the data “looks good”). Some labs might plan to test additional babies beyond the primary sample (e.g., with additional manipulations). These data will not be included in our primary planned analyses, and will not count toward the minimum contribution, but these additional datasets are welcome, and we encourage researchers to preregister other hypotheses. You are free to publish these “side studies” on your own terms, but please keep in mind the restrictions on publishing the main dataset if you are using it as a comparison/control sample (see the section on Open Science Policies in the MB General Manual). 2.5 Procedure Please adhere to the following specifications for conducting this study. If any of the following technical specifications are not possible for your lab, please contact the MB5 leadership team (mb5@manybabies.org) before beginning data collection to inform us of your planned deviation and the reason for it. 2.5.1 Caregiver bias and instruction Caregivers should be masked from viewing the visual stimulus using your lab’s standard method (e.g., having caregivers wear taped-over sunglasses). It is not necessary to block parents’ hearing of the audio stimulus. Instruct parents NOT to point to the lights or screen, shift their bodies, or move their chairs if the baby is inattentive. Emphasize during the instruction/setup that infants’ boredom with some of the stimuli is part of the experiment and is OK. Suggestion: to ensure that the infant and parent are as comfortable as possible, you may tell the parent that it is okay to shift their or their baby’s body to a more comfortable position, or provide interaction that the baby is soliciting, but emphasize that this may be done only for a short period during the attention grabber phase (e.g., when they hear the laughing baby). 2.5.2 Collecting participant information We aim to integrate our testing procedure with your lab’s procedure as much as possible, but there is some amount of information that we need to gather in a standardized fashion. Participant information: Please use this Family Background Questionnaire to collect the information. You are welcome to adapt the format as long as the wording is not changed, except as noted: Any areas marked in green you can adapt to ensure they are appropriate to your country/region. However, please keep the wording as similar as possible to ensure consistency in reporting. The question on race/ethnicity can be adapted to meet the norms of your region. If possible, please use racial/ethnic categories taken from local census categories. For countries where it is not considered socially or legally acceptable to inquire about ethnic background, please adapt to a more appropriate question (e.g. parent and child place of birth), if possible. Translations into other languages will be available here as they are created. If you need to make changes other than as indicated above, please contact the leadership team to discuss your concerns. Let us know if any of the questions are unclear to you - it is important that you are able to answer any questions the participants may have. Please also check the participants’ answers to avoid blank responses. If you modify any of the wording in the form, even in the green sections, or translate the form to your lab’s local language please upload a blank copy of your form using the MB5 documentation upload form. Please ensure that your form is clearly labeled in the filename with your LabID (e.g. babylabPrinceton_background.pdf). 2.5.3 Experimenter blindness The experimenter should be masked fromblind to trial details, by being either (1) in a different room, with no way of knowing which stimuli the baby is seeing on each trial, or (2) in the same room but facing away from the stimuli and unaware of what is on the screen. 2.5.4 Sound volume Your lab can use whatever volume level has been used successfully in the past, but please standardize your volume for this study so that every baby gets stimuli at the same volume. 2.5.5 Familiarization Infant-Controlled Version (preferred version of data collection): The visual stimulus is displayed until the infant accumulates 5, 10, or 15 seconds of looking (depending on familiarization condition). Infants’ looking to the screen is tracked online in one of two ways: (1) automatically (e.g., using eye tracking methods); or (2) manually (e.g., experimenter presses a button while the infant is looking and releases when the infant looks away). Fixed-Length/Duration Version: The visual stimulus is displayed for 5, 10, or 15 seconds (depending on familiarization condition) regardless of the duration of infants’ looking. Infants’ looking to the screen may be measured offline (e.g., via later video coding) or online (e.g., experimenter presses a button while the infant is looking and releases when the infant looks away) to assess how much the infant actually looked to the stimulus during familiarization. 2.5.6 Test Infant-Controlled Version (preferred version of data collection): Circle &amp; chimes attention getter plays until the infant fixates for at least 500 ms total (can be accumulated across multiple looks). After 500 ms is accumulated, the stimulus to which the infant was familiarized is presented alongside a novel stimulus (drawn from the same stimulus class (fribbles or fractals) and complexity level (low-complexity or high-complexity). The pair is presented for 5 s, regardless of how much the infant looks to the stimuli (i.e., duration of the test trials is fixed regardless of whether labs are using the infant-controlled or fixed-length version). Circle &amp; chimes attention getter plays again until the infant fixates for at least 500 ms total (can be accumulated across multiple looks). After 500 ms is accumulated, the same stimulus pair is presented for an additional 5s (regardless of how much the infant looks to the stimuli) with the side of familiar and novel stimulus reversed. Infants’ looking during test is calculated either: (1) automatically (if using an eyetracker); or (2) manually offline (e.g., coded from video data). Because it is challenging to manually code the side to which an infant is looking online, we request that labs who are not using an eyetracker code infants’ looking during the test phase offline. Fixed-Length/Duration Version: Circle &amp; chimes attention getter plays for 750 ms (note that this is longer than the infant-controlled version to give infants time to fixate the central stimulus). After 750 ms, the stimulus to which the infant was familiarized is presented alongside a novel stimulus (drawn from the same stimulus class (fribbles or fractals) and complexity level (low-complexity or high-complexity). The pair is presented for 5 s, regardless of how much the infant looks to the stimuli (i.e., duration of the test trials is fixed regardless of whether labs are using the infant-controlled or fixed-length version). Circle &amp; chimes attention getter plays again for 750 ms. After 750 ms, the same stimulus pair is presented for an additional 5s (regardless of how much the infant looks to the stimuli) with the side of familiar and novel stimulus reversed. Infants’ looking during test is calculated manually offline (e.g., coded from video data). 2.6 General lab practices 2.6.1 Training research assistants You are responsible for implementing rigorous training practices. Research assistants should be held to the same high standards for ManyBabies as they would be for your main studies. You are free to have any number of research assistants conduct the test sessions, but please aim for as much coding consistency as possible and document which research assistant coded a given baby (using code names such as RA1, RA2, etc. if you wish). You will be asked to report about your standard training practices (e.g., how/when do you determine it’s okay for a research assistant to test real babies). Online Coding. If you are using a central screen to gather accumulated looking data for infant-controlled familiarization, then research assistants will need to be properly trained in coding online looking behaviors. Offline Coding. If you are not using an eyetracker to gather data, then you will need to code the test trials offline. Greeting families You can greet families, briefly explain the study’s purpose and goals in terms understandable to families (avoid technical jargon), obtain informed consent, and conduct the appointment as you normally would. Acknowledge their decision to consider participating and express appreciation for their time. Address potential concerns families might have and answer their questions openly and honestly. 2.6.2 Compensating families You can use your lab’s standard, IRB-approved method for compensating families. This can include providinge small gifts, cash, travel reimbursement, taxi rides, or other incentives for participation as you normally would. Participating labs are responsible for compensating their own participants. 2.6.3 Walkthrough video Before beginning data collection, you are required to create a walkthrough video and submit it for approval. Instructions can be found here. Upload your walkthrough video: Walkthrough videos should be uploaded to this google drive folder. Please ensure that your video is clearly labeled in the filename with your LabID (e.g. babylabPrinceton_walkthrough.mpg). "],["general-lab-practices-1.html", "3 General Lab Practices 3.1 Training research assistants 3.2 Greeting families 3.3 Compensating families 3.4 Walkthrough video", " 3 General Lab Practices 3.1 Training research assistants You are responsible for implementing rigorous training practices. Research assistants should be held to the same high standards for ManyBabies as they would be for your main studies. You are free to have any number of research assistants conduct the test sessions, but please aim for as much coding consistency as possible and document which research assistant coded a given baby (using code names such as RA1, RA2, etc. if you wish). You will be asked to report about your standard training practices (e.g., how/when do you determine it’s okay for a research assistant to test real babies). Online Coding. If you are using a central screen to gather accumulated looking data for infant-controlled familiarization, then research assistants will need to be properly trained in coding online looking behaviors. Offline Coding. If you are not using an eyetracker to gather data, then you will need to code the test trials offline. 3.2 Greeting families You can greet families, briefly explain the study’s purpose and goals in terms understandable to families (avoid technical jargon), obtain informed consent, and conduct the appointment as you normally would. Acknowledge their decision to consider participating and express appreciation for their time. Address potential concerns families might have and answer their questions openly and honestly. 3.3 Compensating families You can use your lab’s standard, IRB-approved method for compensating families. This can include providinge small gifts, cash, travel reimbursement, taxi rides, or other incentives for participation as you normally would. Participating labs are responsible for compensating their own participants. 3.4 Walkthrough video Before beginning data collection, you are required to create a walkthrough video and submit it for approval. Instructions can be found here. Upload your walkthrough video: Walkthrough videos should be uploaded to this google drive folder. Please ensure that your video is clearly labeled in the filename with your LabID (e.g. babylabPrinceton_walkthrough.mpg). "],["prior-to-data-collection-checklist.html", "4 Prior to data collection checklist", " 4 Prior to data collection checklist The steps for getting started are tracked by the MB5 leadership team on the MB5 Project Tracker. You can check it to see what steps your lab has completed. If you have any questions or think your lab’s progress is not up-to-date, contact us (mb5@manybabies.org). After preparing your lab and BEFORE BEGINNING DATA COLLECTION you need to: Complete the Initial Sign-Up Form (if you have not already done so). Confirm ethics approval is uploaded: Make sure that a copy of your lab’s ethics approval is in this google drive folder. If you plan to share participant videos via Databrary, you should also make sure you are getting proper consent for video sharing (please include approval for video sharing in ethics upload). Confirm demographics form is uploaded: Make sure that a copy of your lab’s demographics formethics approval is in this google drive folder. Confirm walkthrough video is and demographics form uploaded (if needed): Make sure that a copy of your lab’s walkthrough video is in this google drive folder, and your laboratory demographics form in this google drive folder. Complete the Lab Questionnaire: Make sure someone from your lab has filled out the Lab Questionnaire with details about your laboratory. The leadership will be notified of your submission of the Lab Questionnaire after which they will start the approval/greenlighting process. Convert dummy or pilot data into the right format for submission (see details below) using the MB Data validator to check data validity; in case of questions, please contact the analysis team. This ensures that you will be ready to submit your lab’s data to the central analysis team! Send email to Jessica Kosie (jkosie@asu.edu) to let the leadership know that you are ready for ‘greenlighting’. Wait until you receive an official go-ahead from Project Leads before you begin testing. We may have questions for you, e.g. about your planned protocol deviations. We will do our best to respond quickly, but Iif you don’t hear from us within a week of sending the email, please contact us again!. "],["during-data-collection.html", "5 During data collection 5.1 Running the experiment 5.2 Exclusions and reporting errors and infant “fuss-outs” 5.3 Peeking and stopping rules", " 5 During data collection 5.1 Running the experiment 5.1.1 Restarts, recalibration (eye-tracker) and pauses Any pauses in the procedure can potentially lead to an erasure of the weak memory trace for the familiarization stimuli (Gerken, p.c. noticed a loss of effect if there is a 30+ second pause between familiarization and test phase). Therefore, we ask: NO RESTARTS. Do not restart any trials, regardless of short looking, fussiness, experimental error, etc. Very short trials will be excluded centrally during the analysis process, but should be fully reported and not repeated. DO NOT RECALIBRATE (eyetrackers) once the session has started. Pauses: If babies are fussy, it can be necessary to attempt to get them settled. You may use the natural pause of an attention getter to let the parent non-verbally resettle their baby for a very short time (a couple of seconds, according to your practices). However, longer pauses should result in the cessation of the study. Suggestion: if the baby is fussy and you would like to try to continue the experiment after the baby calms down just so that the parent gets the full experience, you are welcome to do so, but this data must be excluded. For these babies, you would report any data collected before the actual experiment terminated from fuss-out/inattention, not the repeat or continued demonstration. 5.2 Exclusions and reporting errors and infant “fuss-outs” Decisions regarding discards for experimental reasons will be made centrally and need to be reported consistently, hence it is important to retain all data from all infants that entered the testing room. Specifically, the data you send in for central analysis should use the “toe in the testing room” standard: if the infant made it so far as the testing room, the Pparticipant Data files dataset should include their data. In ManyBabies studies, we do not discard “partial data.” It is important for both reporting purposes and potential secondary analyses to have full information about both “usable” and “unusable” trials, even for infants who did not complete or provide usable data for all familiarization and test trials. Trial-level exclusions may not result in the exclusion of the participant from the dataset. These instructions are counter to many labs’ normal internal practices, so please ensure that RAs are fully trained on this element. There are specific columns in the data templates to report the reasons that some of this data should not be included in the main analysis; every lab is expected to report at least some ‘unusable’ data! 5.2.1 Session-level and trial-level errors There are two possible kinds of exclusion: session-level (exclude all data from this participant from analysis) and trial-level (exclude just this trial, e.g. because there was interference or the baby had already fussed out). Session-level errors are reported in the Participant Data file and trial-level errors are reported in the Trial Data file. Most lab-reported errors will be “trial-level” errors. If the infant completed any trials, please do NOT report the infant as a session-level error EVEN IF YOU LATER REALIZE THE CHILD DOES NOT MEET ALL INCLUSION CRITERIA. Medical issues and developmental concerns. Please do not exclude based on medical issues / developmental concerns. Instead, provide sufficient detail in the ‘medical_issue’and/or ’developmental_concern’ fields for the analysis team to review and categorize centrally. As with all exclusions, it is important to include these in your data if the infant entered the testing room. For clear-cut judgements such as age, please just use the appropriate columns to report the values that would result in exclusion (e.g. “age = 3 years”). For subjective judgements such as whether the baby was too fussy, the central decision will be made based on the original coder/RA’s judgment, since it would be impractical to review comments/videos and make the decision centrally. Therefore, please be very clear (but succinct) in the ‘trial_error_info’ and ‘session_error_info’ fields about whether a given trial should be discarded and why. Please classify as one of the listed ‘Value example’ options in the Data Dictionary where possible. Use the “other” category sparingly and only if absolutely necessary. In the ‘notes’ column, please provide further succinct but sufficient information so that it is clear why a given trial or infant was excluded (e.g. “mom pointed at the screen”). Remember that this will be the only information that will be available to the analysis team as they compile and analyze the dataset; ambiguous entries will be problematic for data analysis! Session-level errors: Session level errors are those which result in discarding the data for a participant completely. Session level errors include: Fuss-out after entering the testing room but prior to starting the experiment Parental interference affecting ALL trials (e.g. caregiver refuses to wear the eye covering properly through all trials, or chronically failing to comply with experimenter instructions such that the validity of the entire session is in question). Experimenter error that makes the entire session unuseable (e.g. ran the wrong test session). Equipment failure that makes the entire session unuseable (e.g. video was not playing properly) Failure to calibrate (eyetrackers only) Infant was tested but was found to not meet the inclusion criteria (e.g. vision issues reported on the demographics questionnaire). Only in cases where infants did not start the experiment (i.e., did not see any stimuli) due to fuss-out or equipment/calibration failure, labs are welcome to reschedule the appointment to another occasion; please indicate this in the participant data form. With regards to session-level errors: Please make sure to include participants excluded for session-level errors in your Participant Data file. You do not need to report them in the Trial Data file (see below for details about the required formats of these files). Data from infants where session-level errors are reported do NOT count towards the minimum sample size. Please do NOT mark a participant as a “session-level” error if an infant entered the testing room and completed the first familiarization phase even if they provided no usable test trial data. Trial-level errors: Trial-level errors are those which result in discarding the data for a single trial. Each of the 12 test trials should be marked as either ‘no error’ (usable) or ‘error’ (to be discarded). Trials with no usable data should have ‘NA’ marked in their data columns. Your lab will make the decision and report whether a trial should be excluded, as well as the reason why. These can include temporary instances of issues such as: parental interference in the middle of the experiment (e.g. mother speaks to infant during a trial and gets their attention) experimenter error or equipment failure that affects one or more trials but not the entire session transitory infant fussiness involving only a very brief pause in testing (see below for further details on reporting), or fussiness where the infant “fusses out” after the initiation of one or more test trials With regards to trial-level errors note: For transitory fussiness, ONLY mark the trials on which the infant was actually fussy - further exclusions may be implemented centrally, but it is important that any potentially usable trials after a transitory fussiness period be included in the submitted data. For example, if the infant was fussy on trials 8 and 10 but not trials 1-7,9,11 and 12, only trials 8 and 10 should be marked as an exclusion. If the infant provides some usable trials and then “fusses out” so that the study is terminated prematurely, please make this clear by marking ‘NA’ on trials that were not given. Trial level errors resulting in further exclusion: In most cases, trial level exclusions should result in exclusion ONLY of the trial immediately impacted by the exclusion (e.g. transitory fussiness, parent distracting baby by scratching their nose). However, in some cases, it may be necessary to exclude all subsequent trials, because of concerns that the infant is no longer “on task”. If this is the case, please mark all subsequent trials as trial level errors and explain the reasoning in the notes. Some examples of this type of situation: Any time (due to fussiness or other reasons) there is a break between trials of more than a few seconds. Equipment failure that raises concerns about the validity of subsequent trials. Significant parental interference/engagement or external noise that diverts the infant’s attention to the extent that it raises concerns about the infant being distracted across all trials. Note that we have included a test in the robustness checking section of the manuscript about the effect of discarding trials after an initial excluded trial. 5.3 Peeking and stopping rules In your initial commitment to a recruitment block (in the laboratory questionnaire), you will document your recruitment practices, your initial plan regarding how many babies you will run and of what type, as well as your stopping rule (e.g. stop when I reach the specified N, stop when the study data collection time ends). It is important to document any changes to your recruitment/stopping rule with a “protocol change form”. IMPORTANT: It is critical for the integrity of the data analysis that you NOT base any decisions about how many babies to run on the data being generated in your lab, or on the number of participant exclusions. Laboratories should stick with their original “stopping rule” - whether based on a number of participants or testing time frame. However, we recognize that this may not always be possible. In extraordinary circumstances, decisions about changes to the sample size and stopping rule must be made by someone who has not viewed the emerging data. You can look (if necessary, e.g. to support a student interim report) but you MUST NOT change your recruitment goals and strategy based on your view of the data. Doing this will compromise the goals of the project! If you change your recruitment based on the data, that invalidates the statistical inferences we want to make and introduces exactly the kinds of biases into the data that this project was designed to avoid. If your lab is running pre-specified pilot participants (e.g., to practice the procedure), you may make minor procedural adjustments during that period only. "],["after-data-collection.html", "6 After data collection 6.1 Publishing 6.2 404 pages 6.3 Metadata for sharing", " 6 After data collection 6.1 Publishing HTML books can be published online, see: https://bookdown.org/yihui/bookdown/publishing.html 6.2 404 pages By default, users will be directed to a 404 page if they try to access a webpage that cannot be found. If you’d like to customize your 404 page instead of using the default, you may add either a _404.Rmd or _404.md file to your project root and use code and/or Markdown syntax. 6.3 Metadata for sharing Bookdown HTML books will provide HTML metadata for social sharing on platforms like Twitter, Facebook, and LinkedIn, using information you provide in the index.Rmd YAML. To setup, set the url for your book and the path to your cover-image file. Your book’s title and description are also used. This gitbook uses the same social sharing data across all chapters in your book- all links shared will look the same. Specify your book’s source repository on GitHub using the edit key under the configuration options in the _output.yml file, which allows users to suggest an edit by linking to a chapter’s source file. Read more about the features of this output format here: https://pkgs.rstudio.com/bookdown/reference/gitbook.html Or use: ?bookdown::gitbook "],["additional-chapter.html", "7 Additional Chapter 7.1 Here’s the next chapter", " 7 Additional Chapter 7.1 Here’s the next chapter Wow, really insightful!! "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
